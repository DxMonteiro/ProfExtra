{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY6dNLF67CBm"
      },
      "source": [
        "# Stage 0: Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tICmwnRaXBQ",
        "outputId": "9b2e2271-c426-4472-dd9a-f8bdec64fa61"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/dxmonteiro/miniconda3/envs/profextra/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2022-10-24 20:47:19.305710: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-10-24 20:47:19.957592: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-10-24 20:47:20.957851: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2022-10-24 20:47:20.957944: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2022-10-24 20:47:20.957952: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2022-10-24 20:47:24.201051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-10-24 20:47:24.201231: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
            "2022-10-24 20:47:24.201278: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "2022-10-24 20:47:24.201318: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
            "2022-10-24 20:47:24.201357: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
            "2022-10-24 20:47:24.201397: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
            "2022-10-24 20:47:24.201433: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
            "2022-10-24 20:47:24.201465: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import random\n",
        "import json\n",
        "import numpy as np\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\n",
        "from gensim.summarization import keywords\n",
        "from keybert import KeyBERT\n",
        "from rake_nltk import Rake\n",
        "import yake\n",
        "import spacy\n",
        "import pke\n",
        "import textstat\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd34rGqO7Gy9"
      },
      "source": [
        "# Stage 1: Extract Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYNAwrQpvgar"
      },
      "source": [
        "1.1. Global Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JYnVuG_9LoSv"
      },
      "outputs": [],
      "source": [
        "dataset_scopus = \"/home/dxmonteiro/Desktop/WORKSPACE/ProfExtra/input/humanidades_digitais_scopus.csv\"\n",
        "\n",
        "title = 0\n",
        "citations = 1\n",
        "doi = 2\n",
        "link = 3\n",
        "abstract = 4\n",
        "keywords = [5,7,9,11,13,15,17,19]\n",
        "authors = [21,22,23,24,25,26,27,28,29,30,31,32,33,34,35]\n",
        "\n",
        "list_papers = []\n",
        "list_authors = []\n",
        "list_keywords = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M89zaHqpvjpC"
      },
      "source": [
        "1.2. Auxiliar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mnU6XrJqYu6m"
      },
      "outputs": [],
      "source": [
        "def update_list(elementa, list_authors, citations):\n",
        "  k = 0\n",
        "  for check in list_authors:\n",
        "    if check.get('name') == elementa:\n",
        "      author = {\n",
        "        'name': elementa,\n",
        "        'frequence': check.get('frequence') + 1,\n",
        "        'citations': check.get('citations') + citations\n",
        "      }\n",
        "      list_authors[k] = author\n",
        "      return True\n",
        "    k += 1\n",
        "  return False\n",
        "\n",
        "def get_values(real_authors, list_authors, citations):\n",
        "  for elementa in real_authors:\n",
        "    if update_list(elementa, list_authors, citations) == False:\n",
        "      author = {\n",
        "        'name': elementa,\n",
        "        'frequence': 1,\n",
        "        'citations': citations\n",
        "      }\n",
        "      list_authors.append(author)\n",
        "  return list_authors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6owzIxEvlPG"
      },
      "source": [
        "1.3. Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4CJ8667q7OAH"
      },
      "outputs": [],
      "source": [
        "with open(dataset_scopus, 'r') as file:\n",
        "  csvreader = csv.reader(file)\n",
        "  next(csvreader)\n",
        "  for row in csvreader:\n",
        "    if not not row[citations]:\n",
        "      nplist = np.array(row)\n",
        "      real_authors = list(filter(None, nplist[authors]))\n",
        "      real_keywords = list(filter(None, nplist[keywords]))\n",
        "      new_cit = int(row[citations])\n",
        "      paper = {\n",
        "          'doi': nplist[doi],\n",
        "          'title': nplist[title],\n",
        "          'abstract': nplist[abstract],\n",
        "          'link': nplist[link],\n",
        "          'citations': new_cit,\n",
        "          'keywords': real_keywords,\n",
        "          'authors': real_authors\n",
        "      }\n",
        "      list_papers.append(paper)\n",
        "      list_authors = get_values(real_authors, list_authors, new_cit)\n",
        "      list_keywords = get_values(real_keywords, list_keywords, new_cit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKuqT4GvvnvR"
      },
      "source": [
        "1.4. Testing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR20qb-DxJZw",
        "outputId": "ccfd8414-3451-44d5-dc7a-23dd5b3db1aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Papers: 1895\n",
            "Sample of Papers:\n",
            "0: {'doi': '10.2979/victorianstudies.64.2.12', 'title': 'Sara Ahmed’s Politics of Citation and Student Scholarship: Uncovering Indigenous Coauthors of British Folklore Collections', 'abstract': 'In 2021, I taught an introductory literary seminar in which students read the folklore of colonized subjects and supernatural fiction by writers of color who had lived under British rule or Western imperial influence. We partnered with Adrian Wisnicki’s digital humanities project One More Voice to create an online anthology and video series that critically frame folklore collections from Japan, India, South Africa, and Jamaica. The students learned about Sara Ahmed’s politics of citation and applied her ideas in giving credit to the Indigenous coauthors who sourced, transcribed, and translated oral folktales for British colonizers. I argue that we should regard the students as scholars who modeled ways of undisciplining Victorian studies in their work on Lafcadio Hearn and Setsu Koizumi’s Kottō (1902). © 2022 The Trustees of Indiana University.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136995886&doi=10.2979%2fvictorianstudies.64.2.12&partnerID=40&md5=a8f0e9f8abd8700e71cb7195ad0988c1', 'citations': 0, 'keywords': [], 'authors': ['Ohri I.']}\n",
            "1: {'doi': '10.1186/s40494-022-00750-1', 'title': 'A practical workflow for the 3D reconstruction of complex historic sites and their decorative interiors: Florence As It Was and the church of Orsanmichele', 'abstract': 'The Digital Humanities project Florence As It Was (http://florenceasitwas.wlu.edu) seeks to reconstruct the architectural and decorative appearance of late Medieval and early Modern buildings by combining 3D point cloud models of buildings (i.e. extant structures such as chapels, churches, etc.) with 3D rendered models of artworks that were installed inside them during the fourteenth and fifteenth centuries. This paper documents a novel bifurcated workflow that allows the construction of such integrated 3D models as well as an example case study of a church in Florence, Italy called Orsanmichele (https://3d.wlu.edu/v21/pages/orsanmichele2.html). The key steps worked out in the optimized workflow include: (1) art historical research to identify the original artworks in each building, (2) the use of LiDAR scanners to obtain 3D data (along with associated color information) of the interiors and exteriors of buildings, (3) the use of high resolution photogrammetry of works of art (i.e. paintings and sculptures) which have been removed from those buildings and are now in public collections, (4) the generation of point clouds from the 3D data of the buildings and works of art, (5) the editing and cojoining of a textured polygon model of artworks with a reduced size (using novel algorithms) point cloud model of the buildings in an open-source software tool called Potree so that artworks can be embedded in their original architectural settings, and (6) the annotation of these models with scholarly art historical texts that present viewers immediate access to information, archival evidence, and historical descriptions of these spaces. The integrated point cloud and textured models of buildings and artworks, respectively, plus annotations are then published with Potree. This process has resulted in the development of highly accurate virtual reconstructions of key monuments from the Florentine Middle Ages and Renaissance (like the fourteenth century building of Orsanmichele and the multiple paintings that were once inside it) as they originally appeared. The goal of this project is to create virtual models for scholars and students to explore research questions while providing key information that may assist in generating new projects. Such models represent a significant tool to allow improved teaching of art and architectural history. Furthermore, since the assigned location of some of the historic artworks within these sites are not always firmly known, the virtual model allows users to experiment with potential arrangements of objects in and on the buildings they may have originally decorated. © 2022, The Author(s).', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135140533&doi=10.1186%2fs40494-022-00750-1&partnerID=40&md5=899f1da57f37c23d2c9b6719952e2d47', 'citations': 0, 'keywords': ['Digital humanities', 'Florence', 'LiDAR', 'Model', 'Orsanmichele', 'Photogrammetry', 'Potree', 'Scan'], 'authors': ['Bent G.R.', 'Pfaff D.', 'Brooks M.', 'Radpour R.', 'Delaney J.']}\n",
            "2: {'doi': '10.1186/s40494-022-00708-3', 'title': 'PROTEUS: an immersive tool for exploring the world of cultural heritage across space and time scales', 'abstract': 'In the field of digital humanities, it is increasingly necessary to develop and validate virtual reality tools that are capable of combining various scientific data in a virtualized context providing also access and user friendly consultation of online repositories. This paper reports the main aspects of the implementation of a virtual reality tool integrated with an online repository for storing 3D models, metadata and chemical analyses related to different sectors of digital humanities. The virtual reality software, developed for the Oculus Quest 2 hardware, is called PROTEUS and allows for seamless transition from the macroscopic world of digital humanities to the microscopic world of molecular sciences. The paper illustrates, by means of some case studies, the performances of this innovative tool that permits the researcher to understand and manipulate objects, to test hypotheses and to seek meaningful results, visualising the metadata while changing the parameters of the simulation in a dynamic and interactive way. This represents also a significant step forward in the democratisation of science, thanks to an user-friendly and immersive access to advanced scientific algorithms, which allow the natural perception of structural and topological features of the underlying molecular and supra-molecular systems. Graphical Abstract: [Figure not available: see fulltext.]. © 2022, The Author(s).', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131002133&doi=10.1186%2fs40494-022-00708-3&partnerID=40&md5=b2cb61b330b3a31de3cdda1eec8dea26', 'citations': 0, 'keywords': ['3D technologies', 'Archaeology', 'Digital humanities', 'Intangible cultural heritage', 'Virtual reality'], 'authors': ['Albertini N.', 'Baldini J.', 'Dal Pino A.', 'Lazzari F.', 'Legnaioli S.', 'Barone V.']}\n",
            "3: {'doi': '10.1007/s11263-022-01664-y', 'title': 'A Deep Learning Approach to Clustering Visual Arts', 'abstract': 'Clustering artworks is difficult for several reasons. On the one hand, recognizing meaningful patterns based on domain knowledge and visual perception is extremely hard. On the other hand, applying traditional clustering and feature reduction techniques to the highly dimensional pixel space can be ineffective. To address these issues, in this paper we propose DELIUS: a DEep learning approach to cLustering vIsUal artS. The method uses a pre-trained convolutional network to extract features and then feeds these features into a deep embedded clustering model, where the task of mapping the input data to a latent space is jointly optimized with the task of finding a set of cluster centroids in this latent space. Quantitative and qualitative experimental results show the effectiveness of the proposed method. DELIUS can be useful for several tasks related to art analysis, in particular visual link retrieval and historical knowledge discovery in painting datasets. © 2022, The Author(s).', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136160398&doi=10.1007%2fs11263-022-01664-y&partnerID=40&md5=80538a8242cf6b978985bf8e89c1f2d6', 'citations': 2, 'keywords': ['Autoencoders', 'Computer vision', 'Cultural heritage', 'Deep clustering', 'Digital humanities', 'Visual arts'], 'authors': ['Castellano G.', 'Vessio G.']}\n",
            "4: {'doi': '10.1109/TPAMI.2021.3092688', 'title': 'Measuring Human Perception to Improve Handwritten Document Transcription', 'abstract': 'In this paper, we consider how to incorporate psychophysical measurements of human visual perception into the loss function of a deep neural network being trained for a recognition task, under the assumption that such information can reduce errors. As a case study to assess the viability of this approach, we look at the problem of handwritten document transcription. While good progress has been made towards automatically transcribing modern handwriting, significant challenges remain in transcribing historical documents. Here we describe a general enhancement strategy, underpinned by the new loss formulation, which can be applied to the training regime of any deep learning-based document transcription system. Through experimentation, reliable performance improvement is demonstrated for the standard IAM and RIMES datasets for three different network architectures. Further, we go on to show feasibility for our approach on a new dataset of digitized Latin manuscripts, originally produced by scribes in the Cloister of St. Gall in the the 9th century. © 1979-2012 IEEE.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112169268&doi=10.1109%2fTPAMI.2021.3092688&partnerID=40&md5=a05afed30a1af3d77b69c1c34595b880', 'citations': 0, 'keywords': ['deep learning', 'digital humanities', 'Document transcription', 'visual psychophysics', 'visual recognition'], 'authors': ['Grieggs S.', 'Shen B.', 'Rauch G.', 'Li P.', 'Ma J.', 'Chiang D.', 'Price B.', 'Scheirer W.J.']}\n",
            "5: {'doi': '10.1109/TVCG.2021.3067200', 'title': 'Interactive Visual Exploration of Longitudinal Historical Career Mobility Data', 'abstract': 'The increased availability of quantitative historical datasets has provided new research opportunities for multiple disciplines in social science. In this article, we work closely with the constructors of a new dataset, CGED-Q (China Government Employee Database-Qing), that records the career trajectories of over 340,000 government officials in the Qing bureaucracy in China from 1760 to 1912. We use these data to study career mobility from a historical perspective and understand social mobility and inequality. However, existing statistical approaches are inadequate for analyzing career mobility in this historical dataset with its fine-grained attributes and long time span, since they are mostly hypothesis-driven and require substantial effort. We propose CareerLens, an interactive visual analytics system for assisting experts in exploring, understanding, and reasoning from historical career data. With CareerLens, experts examine mobility patterns in three levels-of-detail, namely, the macro-level providing a summary of overall mobility, the meso-level extracting latent group mobility patterns, and the micro-level revealing social relationships of individuals. We demonstrate the effectiveness and usability of CareerLens through two case studies and receive encouraging feedback from follow-up interviews with domain experts. © 1995-2012 IEEE.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103234851&doi=10.1109%2fTVCG.2021.3067200&partnerID=40&md5=451e3980bac018ca94d31e343585d6b9', 'citations': 3, 'keywords': ['career mobility', 'Digital humanities', 'quantitative history', 'visual analytics'], 'authors': ['Wang Y.', 'Liang H.', 'Shu X.', 'Wang J.', 'Xu K.', 'Deng Z.', 'Campbell C.', 'Chen B.', 'Wu Y.', 'Qu H.']}\n",
            "6: {'doi': '10.1108/AJIM-09-2021-0278', 'title': 'A spatio-temporal emotional framework for knowledge extraction and mining in digital humanities', 'abstract': \"Purpose: This paper aims to construct a spatio-temporal emotional framework (STEF) for digital humanities from a quantitative perspective, applying knowledge extraction and mining technology to promote innovation of humanities research paradigm and method. Design/methodology/approach: The proposed STEF uses methods of information extraction, sentiment analysis and geographic information system to achieve knowledge extraction and mining. STEF integrates time, space and emotional elements to visualize the spatial and temporal evolution of emotions, which thus enriches the analytical paradigm in digital humanities. Findings: The case study shows that STEF can effectively extract knowledge from unstructured texts in the field of Chinese Qing Dynasty novels. First, STEF introduces the knowledge extraction tools – MARKUS and DocuSky – to profile character entities and perform plots extraction. Second, STEF extracts the characters' emotional evolutionary trajectory from the temporal and spatial perspective. Finally, the study draws a spatio-temporal emotional path figure of the leading characters and integrates the corresponding plots to analyze the causes of emotion fluctuations. Originality/value: The STEF is constructed based on the “spatio-temporal narrative theory” and “emotional narrative theory”. It is the first framework to integrate elements of time, space and emotion to analyze the emotional evolution trajectories of characters in novels. The execuability and operability of the framework is also verified with a case novel to suggest a new path for quantitative analysis of other novels. © 2022, Emerald Publishing Limited.\", 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127797911&doi=10.1108%2fAJIM-09-2021-0278&partnerID=40&md5=6c020b81ee9b8b401d545d50a9c8eb37', 'citations': 0, 'keywords': ['Digital humanities', 'Knowledge extraction', 'Knowledge mining', 'Natural language processing', 'Spatio-temporal emotional analysis'], 'authors': ['Deng J.', 'Zhong C.', 'Sun S.', 'Wang R.']}\n",
            "7: {'doi': '10.13998/j.cnki.issn1002-1248.21-0264', 'title': 'A Construction Method of the Classification System Oriented to Content Analysis of Ancient Books', 'abstract': '[Purpose/Significance] With the deepening of digital humanistic research on ancient books, the requirement for fine-grained classification based on text content is increasing continuously, and reasonable classification has become the key to the research and effective utilization of digital ancient books.[Method/Process] The research uses the concept of faceted classification, takes the text data of ancient books and related dictionary of ancient books as the research object, and combines conceptual semantic information to organize and describe the features of the content of ancient books. [Results/Conclusions] The classification system constructed in this paper breaks through the limitation of the number, genre and type of ancient books. The research selects five dimensions of politics, economy, culture, society and military to organize and reveal the contents of ancient books in an orderly manner, which is of great value to the in-depth development and utilization of digital resources of ancient books. © 2022 Pirogov Russian National Research Medical University. All rights reserved.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126609245&doi=10.13998%2fj.cnki.issn1002-1248.21-0264&partnerID=40&md5=5037e97056e9ff9723ea31ab018c167c', 'citations': 0, 'keywords': ['Digital humanities', 'Digital resource of ancient book', 'Faceted classification', 'Information organization'], 'authors': ['Ai Y.', 'Xu J.', 'He L.', 'Qi Y.']}\n",
            "8: {'doi': '10.13998/j.cnki.issn1002-1248.21-0262', 'title': 'The Trigger Verb Classification Method of Event Sentences in Ancient Chinese Classics Based on Bi-LSTM', 'abstract': '[Purpose/Significance] It is of great significance to carry out research on the recognition and classification of trigger verbs in ancient books oriented to digital humanities for the deep mining and content revealing of ancient texts. This paper uses the deep learning classification algorithm to explore an automated method for multivariate classification of event sentence text based on trigger words in ancient books. [Method/Process] Based on the construction of the classic event trigger word classification system and trigger dictionary, four different types of event sentence texts are selected as experimental data, and the category labels and sentence texts are coded separately using Onehot and Tokenizer, and then the classifier is trained in the Bi-LSTM model, and a comparative experiment is set by adjusting the parameters, and the performance of the classifier is analyzed by using a general evaluation index. [Results/Conclusions] The classifier after many training and adjustments has an accuracy of 0.95 in the evaluation of the test set, which proves that the experimental method based on deep learning and the constructed trigger word data set can effectively help us realize automatic multivariate classification of event sentence text of ancient books. © 2022 Pirogov Russian National Research Medical University. All rights reserved.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126601336&doi=10.13998%2fj.cnki.issn1002-1248.21-0262&partnerID=40&md5=65ac0f9ebe878bae5e6e35573a7a0e3a', 'citations': 0, 'keywords': ['Bi-LSTM model', 'Multivariate classification', 'Trigger word classification', 'Zuo Zhuan'], 'authors': ['Ma X.', 'He L.', 'Liu J.', 'Li Z.', 'Gao D.']}\n",
            "9: {'doi': '10.3390/rel13090793', 'title': 'Testing and Disrupting Ontologies: Using the Database of Religious History as a Pedagogical Tool', 'abstract': 'In an age of “Big Data” the study of the history and archaeology of religion faces an exponentially increasing quantity and range of data and scholarly interpretation. For the student and scholar alike, new tools that allow for efficient and accurate inquiry are a necessity. Here, the open-access and digital Database of Religious History (DRH) is presented as one such tool that addresses this need and is well suited for use in the classroom. In this article, we present the basic structure of the database along with a demonstration of its potential use. Following a thematic inquiry into questions concerning “high gods”, individual disciplinary-specific case studies examine applications to particular contexts across time and space. These case studies demonstrate the ways in which the DRH can test and disrupt ontologies through its ability to efficiently cross traditional disciplinary boundaries. © 2022 by the authors.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138732770&doi=10.3390%2frel13090793&partnerID=40&md5=81b4072e5e649aee122d88342e1d9923', 'citations': 0, 'keywords': ['archaeology', 'database', 'digital humanities', 'high gods', 'history', 'pedagogy', 'religion', 'religious studies'], 'authors': ['Danielson A.J.', 'Arbuckle MacLeod C.', 'Hamm M.J.', 'Canlas G.', 'Randall I.E.', 'Moreiras Reynaga D.K.', 'Weideman J.', 'Monroe M.W.']}\n"
          ]
        }
      ],
      "source": [
        "print('Number of Papers: ' + str(len(list_papers)))\n",
        "print('Sample of Papers:')\n",
        "for i in range(0,10,1):\n",
        "  print(str(i) + ': ' + str(list_papers[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzNQLE0K3ogf",
        "outputId": "305fb6dd-ad78-4c7d-a9ad-a1bc2c22fa64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Authors: 3644\n",
            "Sample of Authors:\n",
            "0: {'name': 'Ohri I.', 'frequence': 1, 'citations': 0}\n",
            "1: {'name': 'Bent G.R.', 'frequence': 1, 'citations': 0}\n",
            "2: {'name': 'Pfaff D.', 'frequence': 1, 'citations': 0}\n",
            "3: {'name': 'Brooks M.', 'frequence': 2, 'citations': 4}\n",
            "4: {'name': 'Radpour R.', 'frequence': 1, 'citations': 0}\n",
            "5: {'name': 'Delaney J.', 'frequence': 1, 'citations': 0}\n",
            "6: {'name': 'Albertini N.', 'frequence': 1, 'citations': 0}\n",
            "7: {'name': 'Baldini J.', 'frequence': 1, 'citations': 0}\n",
            "8: {'name': 'Dal Pino A.', 'frequence': 1, 'citations': 0}\n",
            "9: {'name': 'Lazzari F.', 'frequence': 1, 'citations': 0}\n"
          ]
        }
      ],
      "source": [
        "print('Number of Authors: ' + str(len(list_authors)))\n",
        "print('Sample of Authors:')\n",
        "for i in range(0,10,1):\n",
        "  print(str(i) + ': ' + str(list_authors[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g02ZA7YO6hVS",
        "outputId": "f4a7f4c4-d8f6-4d78-c7bc-2979f7461025"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Keywords: 5146\n",
            "Sample of Keywords:\n",
            "0: {'name': 'Digital humanities', 'frequence': 593, 'citations': 2692}\n",
            "1: {'name': 'Florence', 'frequence': 1, 'citations': 0}\n",
            "2: {'name': 'LiDAR', 'frequence': 1, 'citations': 0}\n",
            "3: {'name': 'Model', 'frequence': 1, 'citations': 0}\n",
            "4: {'name': 'Orsanmichele', 'frequence': 1, 'citations': 0}\n",
            "5: {'name': 'Photogrammetry', 'frequence': 3, 'citations': 1}\n",
            "6: {'name': 'Potree', 'frequence': 1, 'citations': 0}\n",
            "7: {'name': 'Scan', 'frequence': 1, 'citations': 0}\n",
            "8: {'name': '3D technologies', 'frequence': 1, 'citations': 0}\n",
            "9: {'name': 'Archaeology', 'frequence': 12, 'citations': 30}\n"
          ]
        }
      ],
      "source": [
        "print('Number of Keywords: ' + str(len(list_keywords)))\n",
        "print('Sample of Keywords:')\n",
        "for i in range(0,10,1):\n",
        "  print(str(i) + ': ' + str(list_keywords[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv0dLGA4_OiM"
      },
      "source": [
        "# Stage 2: Process Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvFdTDaR16m-"
      },
      "source": [
        "2.1. Get top 10 Papers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUnzCUry1-xK",
        "outputId": "3ca3caae-2f74-4b2c-ba00-06095c714a3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'doi': '10.1177/2053951714528481', 'title': 'Big Data, new epistemologies and paradigm shifts', 'abstract': 'This article examines how the availability of Big Data, coupled with new data analytics, challenges established epistemologies across the sciences, social sciences and humanities, and assesses the extent to which they are engendering paradigm shifts across multiple disciplines. In particular, it critically explores new forms of empiricism that declare ‘the end of theory’, the creation of data-driven rather than knowledge-driven science, and the development of digital humanities and computational social sciences that propose radically different ways to make sense of culture, history, economy and society. It is argued that: (1) Big Data and new data analytics are disruptive innovations which are reconfiguring in many instances how research is conducted; and (2) there is an urgent need for wider critical reflection within the academy on the epistemological implications of the unfolding data revolution, a task that has barely begun to be tackled despite the rapid changes in research practices presently taking place. After critically reviewing emerging epistemological positions, it is contended that a potentially fruitful approach would be the development of a situated, reflexive and contextually nuanced epistemology. © The Author(s) 2014 Reprints and permissions: sagepub.co.uk/journalsPermissions.nav.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073682542&doi=10.1177%2f2053951714528481&partnerID=40&md5=49cbcd64a939cb47af2f8996d0c114a2', 'citations': 1062, 'keywords': ['Big Data', 'computational social sciences', 'data analytics', 'data-driven science', 'digital humanities', 'end of theory', 'epistemology', 'paradigms'], 'authors': ['Kitchin R.']}, {'doi': '10.1007/s11192-014-1229-3', 'title': 'Disciplinary differences in Twitter scholarly communication', 'abstract': 'This paper investigates disciplinary differences in how researchers use the microblogging site Twitter. Tweets from selected researchers in ten disciplines (astrophysics, biochemistry, digital humanities, economics, history of science, cheminformatics, cognitive science, drug discovery, social network analysis, and sociology) were collected and analyzed both statistically and qualitatively. The researchers tended to share more links and retweet more than the average Twitter users in earlier research and there were clear disciplinary differences in how they used Twitter. Biochemists retweeted substantially more than researchers in the other disciplines. Researchers in digital humanities and cognitive science used Twitter more for conversations, while researchers in economics shared the most links. Finally, whilst researchers in biochemistry, astrophysics, cheminformatics and digital humanities seemed to use Twitter for scholarly communication, scientific use of Twitter in economics, sociology and history of science appeared to be marginal. © 2014, Akadémiai Kiadó, Budapest, Hungary.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892447024&doi=10.1007%2fs11192-014-1229-3&partnerID=40&md5=0f4e0be141475ec6e96b15cb15d1be9c', 'citations': 182, 'keywords': ['Altmetrics', 'Disciplinary differences', 'Scholarly communication', 'Twitter', 'Webometrics'], 'authors': ['Holmberg K.', 'Thelwall M.']}, {'doi': '10.1177/1461444812465137', 'title': 'Towards a sociology of computational and algorithmic journalism', 'abstract': 'This article advances a sociological approach to computational journalism. By \"computational journalism\" the article refers to the increasingly ubiquitous forms of algorithmic, social scientific, and mathematical forms of newswork adopted by many 21st-century newsrooms and touted by many educational institutions as \"the future of news.\" By \"sociological approach,\" the article endorses a research model that brackets, at least temporarily, many of the current industry concerns with the practical usability of newsroom analysis. The bulk of the article outlines a series of six lenses through which such an approach to computational journalism might be carried out. Four of these lenses are drawn from Schudson\\'s classic typology of the sociology of news-economic, political, cultural, and organizational approaches. In addition, the author adds Bordieuean field approaches and technological lenses to the mix. In each instance, the author discusses how particular approaches might need to be modified in order to study computational journalism in the digital age. © The Author(s) 2012.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885769193&doi=10.1177%2f1461444812465137&partnerID=40&md5=a20bafd34c1504f04f5c8bdb72857f46', 'citations': 181, 'keywords': ['Computational journalism', 'culture', 'data', 'digital humanities', 'ethnography', 'journalism', 'news institutionalism', 'political economy'], 'authors': ['Anderson C.W.']}, {'doi': '10.1007/s10994-013-5413-0', 'title': 'Interactive topic modeling', 'abstract': 'Topic models are a useful and ubiquitous tool for understanding large corpora. However, topic models are not perfect, and for many users in computational social science, digital humanities, and information studies - who are not machine learning experts - existing models and frameworks are often a \"take it or leave it\" proposition. This paper presents a mechanism for giving users a voice by encoding users\\' feedback to topic models as correlations between words into a topic model. This framework, interactive topic modeling (itm), allows untrained users to encode their feedback easily and iteratively into the topic models. Because latency in interactive systems is crucial, we develop more efficient inference algorithms for tree-based topic models. We validate the framework both with simulated and real users. © 2013 The Author(s).', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901496744&doi=10.1007%2fs10994-013-5413-0&partnerID=40&md5=5e9f7ce6d9daf635fb278501a9243d93', 'citations': 144, 'keywords': ['Feedback', 'Gibbs sampling', 'Interactive topic modeling', 'Latent Dirichlet Allocation', 'Online learning', 'Topic models'], 'authors': ['Hu Y.', 'Boyd-Graber J.', 'Satinoff B.', 'Smith A.']}, {'doi': '10.1108/00220411111109449', 'title': 'Enabled backchannel: conference Twitter use by digital humanists', 'abstract': \"Purpose – To date, few studies have been undertaken to make explicit how microblogging technologies are used by and can benefit scholars. This paper aims to investigate the use of Twitter by an academic community in various conference settings, and to pose the following questions: Does the use of a Twitter\\ue4f8enabled backchannel enhance the conference experience, collaboration and the co\\ue4f8construction of knowledge? and How is microblogging used within academic conferences, and can one articulate the benefits it may bring to a discipline? Design/methodology/approach This paper considers the use of Twitter as a digital backchannel by the Digital Humanities (DH) community, taking as its focus postings to Twitter during three different international 2009 conferences. The resulting archive of 4,574 “Tweets” was analysed using various quantitative and qualitative methods, including a qualitative categorisation of Twitter posts by open coded analysis, a quantitative examination of user conventions, and text analysis tools. Prominent Tweeters were identified and a small qualitative survey was undertaken to ascertain individuals' attitudes towards a Twitter\\ue4f8enabled backchannel. Findings – Conference hashtagged Twitter activity does not constitute a single distributed conversation, but rather multiple monologues with a few intermittent, discontinuous, loosely joined dialogues between users. The digital backchannel constitutes a multidirectional complex space in which the users make notes, share resources, hold discussions and ask questions as well as establishing a clear individual online presence. The use of Twitter as a conference platform enables the community to expand communication and participation in events amongst its members. The analysis revealed the close\\ue4f8knit nature of the DH researcher community, which may be somewhat intimidating for those new to the field or conference. Practical implications This study has indicated that, given that Twitter is becoming increasingly important for academic communities, new, dedicated methodologies for the analysis and understanding of Tweet\\ue4f8based corpora are necessary. Routinely used textual analysis tools cannot be applied to corpora of Tweets in a straightforward manner, due to the creative and fragmentary nature of language used within microblogging. In this paper, a method has been suggested to categorise Tweets using open coded analysis to facilitate understanding of Tweet\\ue4f8based corpora, which could be adopted elsewhere. Originality/value – This paper is the first known exhaustive study that concentrates on how microblogging technologies such as Twitter are used by and can benefit scholars. This data set both provides a valuable insight into the prevalence of a variety of Twitter practices within the constraints of a conference setting, and highlights the need for methodologies to be developed to analyse social media streams such as Twitter feeds. It also provides a bibliography of other research into microblogging. © 2011, Emerald Group Publishing Limited\", 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952292203&doi=10.1108%2f00220411111109449&partnerID=40&md5=63335e5ffd7293ab3b3c3a465d083c7a', 'citations': 144, 'keywords': ['Conferences', 'Digital communication systems', 'Social networks', 'User studies'], 'authors': ['Ross C.', 'Terras M.', 'Warwick C.', 'Welsh A.']}, {'doi': '10.1108/AJIM-09-2013-0094', 'title': 'Programmed method: Developing a toolset for capturing and analyzing tweets', 'abstract': 'Purpose–The purpose of this paper is to introduce Digital Methods Initiative Twitter Capture and Analysis Toolset, a toolset for capturing and analyzing Twitter data. Instead of just presenting a technical paper detailing the system, however, the authors argue that the type of data used for, as well as the methods encoded in, computational systems have epistemological repercussions for research. The authors thus aim at situating the development of the toolset in relation to methodological debates in the social sciences and humanities. Design/methodology/approach–The authors review the possibilities and limitations of existing approaches to capture and analyze Twitter data in order to address the various ways in which computational systems frame research. The authors then introduce the open-source toolset and put forward an approach that embraces methodological diversity and epistemological plurality. Findings–The authors find that design decisions and more general methodological reasoning can and should go hand in hand when building tools for computational social science or digital humanities. Practical implications–Besides methodological transparency, the software provides robust and reproducible data capture and analysis, and interlinks with existing analytical software. Epistemic plurality is emphasized by taking into account how Twitter structures information, by allowing for a number of different sampling techniques, by enabling a variety of analytical approaches or paradigms, and by facilitating work at the micro, meso, and macro levels. Originality/value–The paper opens up critical debate by connecting tool design to fundamental interrogations of methodology and its repercussions for the production of knowledge. The design of the software is inspired by exchanges and debates with scholars from a variety of disciplines and the attempt to propose a flexible and extensible tool that accommodates a wide array of methodological approaches is directly motivated by the desire to keep computational work open for various epistemic sensibilities. © Emerald Group Publishing Limited.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928249663&doi=10.1108%2fAJIM-09-2013-0094&partnerID=40&md5=503326daa805093e265cece8d666ac3d', 'citations': 143, 'keywords': ['Analysis', 'Computational social science', 'Data collection', 'Digital humanities', 'Digital methods', 'Twitter'], 'authors': ['Borra E.', 'Rieder B.']}, {'doi': '10.32614/rj-2016-007', 'title': 'Stylometry with R: A package for computational text analysis', 'abstract': \"This software paper describes 'Stylometry with R' (stylo), a flexible R package for the highlevel analysis of writing style in stylometry. Stylometry (computational stylistics) is concerned with the quantitative study of writing style, e.g. authorship verification, an application which has considerable potential in forensic contexts, as well as historical research. In this paper we introduce the possibilities of stylo for computational text analysis, via a number of dummy case studies from English and French literature. We demonstrate how the package is particularly useful in the exploratory statistical analysis of texts, e.g. with respect to authorial writing style. Because stylo provides an attractive graphical user interface for high-level exploratory analyses, it is especially suited for an audience of novices, without programming skills (e.g. from the Digital Humanities). More experienced users can benefit from our implementation of a series of standard pipelines for text processing, as well as a number of similarity metrics.\", 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010281284&doi=10.32614%2frj-2016-007&partnerID=40&md5=7bc156d9c817b635cf13a9dd554f5ba3', 'citations': 134, 'keywords': [], 'authors': ['Eder M.', 'Rybicki J.', 'Kestemont M.']}, {'doi': '10.1080/01916599.2012.714635', 'title': \"What's the Big Idea? Intellectual History and the Longue Durée\", 'abstract': 'Historians of all kinds are beginning to return to temporally expansive studies after decades of aversion and neglect. There are even signs that intellectual historians are returning to the longue durée. What are the reasons for this revival of long-range intellectual history? And how might it be rendered methodologically robust as well as historically compelling? This article proposes a model of transtemporal history, proceeding via serial contextualism to create a history in ideas spanning centuries, even millennia: key examples come from work in progress on ideas of civil war from ancient Rome to the present. The article concludes with brief reflections on the potential impact of the digital humanities on the practice of long-range intellectual history. © 2012 Copyright Taylor and Francis Group, LLC.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868280635&doi=10.1080%2f01916599.2012.714635&partnerID=40&md5=3b5e264dcffa6a16aad5f2d68dfad625', 'citations': 109, 'keywords': ['Cambridge School', 'civil war', 'conceptual history', 'digital humanities', 'longue durée'], 'authors': ['Armitage D.']}, {'doi': '10.1111/j.1475-5661.2010.00405.x', 'title': 'Mapping the English Lake District: A literary GIS', 'abstract': \"To date, much of the work that uses Geographical Information Systems (GIS) to study human geographies applies a social science paradigm to quantitative data. There is a growing recognition of the need, however, to test whether GIS can be used to map out the qualitative 'data' provided by the articulation of subjective spatial experiences. This paper expands the conceptual possibilities opened up by the use of GIS technology through an exploration of the theoretical potentiality of literary GIS. Drawing on work carried out as part of an interdisciplinary project, 'Mapping the Lakes', the paper focuses on the ways in which GIS can be used to explore the spatial relationships between two textual accounts of tours of the English Lake District: the proto-Picturesque journey undertaken by the poet, Thomas Gray, in the autumn of 1769; and Samuel Taylor Coleridge's self-consciously post-Picturesque 'circumcursion' of August 1802. Alongside this text-specific focus, the paper also draws on recent spatial literary criticism to reflect, more generally, on the critical possibilities and problems associated with the digital mapping of space and place in literature. Ultimately, the paper seeks to open up methodological and critical space for the ongoing development of literary GIS. © 2010 The Authors. Transactions of the Institute of British Geographers © 2010 Royal Geographical Society (with the Institute of British Geographers).\", 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649784112&doi=10.1111%2fj.1475-5661.2010.00405.x&partnerID=40&md5=a49abb3528b15ede2dd5067792dd83e5', 'citations': 93, 'keywords': ['Digital humanities', 'English Lake District', 'GIS', 'Literary cartography', 'Literary studies', 'Spatial theory'], 'authors': ['Cooper D.', 'Gregory I.N.']}, {'doi': '10.1177/0309132512444063', 'title': 'Crossing the qualitative- quantitative divide II: Inventive approaches to big data, mobile methods, and rhythmanalysis', 'abstract': 'In this second of three reports on qualitative and quantitative methods we highlight novel methods with particular purchase on the problems of our time. We again focus on scholarship crossing multiple geographical divides, those of neo/paleo geography, qualitative/quantitative methods, and physical/human geography. We do so now by concentrating on three areas: the emerging digital humanities and the rise of big data, mobile methods, and rhythmanalysis. With this broad approach we seek also to encourage consilience, synergy, and a positive embrace of diversity in geographical scholarship. © The Author(s) 2012.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875024343&doi=10.1177%2f0309132512444063&partnerID=40&md5=515741df9a331ef610192a73dfcc8080', 'citations': 89, 'keywords': ['big data', 'digital humanities', 'inventive methods', 'methodology', 'mobile methods', 'mobilities', 'qualitative', 'quantitative'], 'authors': ['DeLyser D.', 'Sui D.']}]\n"
          ]
        }
      ],
      "source": [
        "list_papers.sort(key=lambda x: x.get('citations'), reverse=True)\n",
        "top_10_papers = list_papers[:10]\n",
        "print(top_10_papers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYuAU1u4z7yr"
      },
      "source": [
        "2.2. Get top 10 Authors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMzOHutPDP7y",
        "outputId": "76f86438-6b58-4ae5-9e22-a65578185695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'name': 'Kitchin R.', 'frequence': 1, 'citations': 1062}, {'name': 'Terras M.', 'frequence': 8, 'citations': 218}, {'name': 'Warwick C.', 'frequence': 5, 'citations': 191}, {'name': 'Holmberg K.', 'frequence': 1, 'citations': 182}, {'name': 'Thelwall M.', 'frequence': 1, 'citations': 182}, {'name': 'Anderson C.W.', 'frequence': 1, 'citations': 181}, {'name': 'Welsh A.', 'frequence': 3, 'citations': 154}, {'name': 'Kestemont M.', 'frequence': 5, 'citations': 147}, {'name': 'Hu Y.', 'frequence': 1, 'citations': 144}, {'name': 'Boyd-Graber J.', 'frequence': 1, 'citations': 144}]\n"
          ]
        }
      ],
      "source": [
        "list_authors.sort(key=lambda x: x.get('citations'), reverse=True)\n",
        "top_10_authors = list_authors[:10]\n",
        "print(top_10_authors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM4rQE9fz_i9"
      },
      "source": [
        "2.3. Get top 10 Keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukkRNWCISZNy",
        "outputId": "5cc72caa-eb02-4a86-b49c-3a64643243cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'name': 'Digital humanities', 'frequence': 593, 'citations': 2692}, {'name': 'Florence', 'frequence': 1, 'citations': 0}, {'name': 'LiDAR', 'frequence': 1, 'citations': 0}, {'name': 'Model', 'frequence': 1, 'citations': 0}, {'name': 'Orsanmichele', 'frequence': 1, 'citations': 0}, {'name': 'Photogrammetry', 'frequence': 3, 'citations': 1}, {'name': 'Potree', 'frequence': 1, 'citations': 0}, {'name': 'Scan', 'frequence': 1, 'citations': 0}, {'name': '3D technologies', 'frequence': 1, 'citations': 0}, {'name': 'Archaeology', 'frequence': 12, 'citations': 30}]\n"
          ]
        }
      ],
      "source": [
        "list_papers.sort(key=lambda x: x.get('citations'), reverse=True)\n",
        "top_10_keywords = list_keywords[:10]\n",
        "print(top_10_keywords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.4. Summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "8y66KCpp2zft",
        "outputId": "835b0fb2-5696-429b-b83c-7043d5e92001"
      },
      "outputs": [],
      "source": [
        "class Summarizer():\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.summarizer = pipeline(\"summarization\", model=self.model)\n",
        "    \n",
        "    def get_summary(self, text):\n",
        "        words = text.split()\n",
        "        totalwords = len(words)\n",
        "        summary = self.summarizer(text, max_length = totalwords, do_sample=False)[0].get('summary_text')\n",
        "        return summary\n",
        "\n",
        "summ_models = ['facebook/bart-large-cnn', 'sshleifer/distilbart-cnn-12-6', 'philschmid/bart-large-cnn-samsum', 'google/pegasus-large', 'sshleifer/distill-pegasus-cnn-16-4']\n",
        "list_papers_summ = []\n",
        "\n",
        "for paper in top_10_papers:\n",
        "  list_summs = []\n",
        "  for sm in summ_models:\n",
        "    ex_summarizer = Summarizer(sm)\n",
        "    head = {\n",
        "        'model': sm,\n",
        "        'summarized_text': ex_summarizer.get_summary(paper.get('abstract'))\n",
        "    }\n",
        "    list_summs.append(head)\n",
        "  new_paper = {\n",
        "    'doi': paper.get('doi'),\n",
        "    'title': paper.get('title'),\n",
        "    'summ_abstract': list_summs,\n",
        "    'link': paper.get('link'),\n",
        "    'citations': paper.get('citations'),\n",
        "    'keywords': paper.get('keywords'),\n",
        "  }\n",
        "  list_papers_summ.append(new_paper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MfgqRUkEI-ix"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summarized Papers:\n",
            "0: {'doi': '10.1177/2053951714528481', 'title': 'Big Data, new epistemologies and paradigm shifts', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'This article examines how the availability of Big Data, coupled with new data analytics, challenges established epistemologies across the sciences, social sciences and humanities. In particular, it critically explores new forms of empiricism that declare ‘the end of theory’ and the creation of data-driven rather than knowledge-driven science.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': ' This article examines how the availability of Big Data, coupled with new data analytics, challenges established epistemologies across the sciences, social sciences and humanities . In particular, it critically explores new forms of empiricism that declare ‘the end of theory’ and the creation of data-driven rather than knowledge-driven science .'}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'Big Data and new data analytics are disruptive innovations which are reconfiguring in many instances how research is conducted. There is an urgent need for a critical reflection within the academy on the epistemological implications of the unfolding data revolution. A potentially fruitful approach would be the development of a situated, reflexive and contextually nuanced epistemology.'}, {'model': 'google/pegasus-large', 'summarized_text': 'This article examines how the availability of Big Data, coupled with new data analytics, challenges established epistemologies across the sciences, social sciences and humanities, and assesses the extent to which they are engendering paradigm shifts across multiple disciplines.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'The availability of Big Data and new data analytics challenges established epistemologies across the sciences, social sciences and humanities . It assesses the extent to which they are engendering paradigm shifts across multiple disciplines .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073682542&doi=10.1177%2f2053951714528481&partnerID=40&md5=49cbcd64a939cb47af2f8996d0c114a2', 'citations': 1062, 'keywords': ['Big Data', 'computational social sciences', 'data analytics', 'data-driven science', 'digital humanities', 'end of theory', 'epistemology', 'paradigms']}\n",
            "1: {'doi': '10.1007/s11192-014-1229-3', 'title': 'Disciplinary differences in Twitter scholarly communication', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'This paper investigates disciplinary differences in how researchers use the microblogging site Twitter. Tweets from selected researchers in ten disciplines were collected and analyzed both statistically and qualitatively. The researchers tended to share more links and retweet more than the average Twitter users in earlier research. Biochemists retweeted substantially more than researchers in the other disciplines.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': ' This paper investigates disciplinary differences in how researchers use Twitter . Tweets from selected researchers in ten disciplines were collected and analyzed both statistically and qualitatively . Biochemists retweeted substantially more than researchers in the other disciplines . Researchers in digital humanities and cognitive science used Twitter more for conversations, while researchers in economics shared the most links .'}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'This paper investigates disciplinary differences in how researchers use the microblogging site Twitter. Tweets from selected researchers in ten disciplines were collected and analyzed both statistically and qualitatively. The researchers tended to share more links and retweet more than the average Twitter user. Biochemists retweeted substantially more than researchers in the other disciplines. Researchers in digital humanities used Twitter more for conversations, while researchers in economics shared the most links.'}, {'model': 'google/pegasus-large', 'summarized_text': 'Finally, whilst researchers in biochemistry, astrophysics, cheminformatics and digital humanities seemed to use Twitter for scholarly communication, scientific use of Twitter in economics, sociology and history of science appeared to be marginal.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'The researchers tended to share more links and retweet more than the average Twitter users . Biochemists retweeted substantially more than researchers in the other disciplines .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892447024&doi=10.1007%2fs11192-014-1229-3&partnerID=40&md5=0f4e0be141475ec6e96b15cb15d1be9c', 'citations': 182, 'keywords': ['Altmetrics', 'Disciplinary differences', 'Scholarly communication', 'Twitter', 'Webometrics']}\n",
            "2: {'doi': '10.1177/1461444812465137', 'title': 'Towards a sociology of computational and algorithmic journalism', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'This article advances a sociological approach to computational journalism. By \"computational journalism\" the article refers to the increasingly ubiquitous forms of algorithmic, social scientific, and mathematical forms of newswork. Four of these lenses are drawn from Schudson\\'s classic typology of the sociology of news-economic, political, cultural, and organizational approaches. In addition, the author adds Bordieuean field approaches and technological lenses to the mix.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': \" This article advances a sociological approach to computational journalism . The bulk of the article outlines a series of six lenses through which such an approach might be carried out . Four of these lenses are drawn from Schudson's classic typology of the sociology of news-economic, political, cultural, and organizational approaches . In each instance, the author discusses how particular approaches might need to be modified .\"}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': \"This article advances a sociological approach to computational journalism. Four of the lenses are drawn from Schudson's classic typology of the sociology of news-economic, political, cultural, and organizational approaches. The author adds Bordieuean field approaches and technological lenses to the mix.\"}, {'model': 'google/pegasus-large', 'summarized_text': 'The bulk of the article outlines a series of six lenses through which such an approach to computational journalism might be carried out.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'The article refers to increasingly ubiquitous forms of algorithmic, social scientific, and mathematical forms of newswork adopted by many 21st-century newsrooms . The article endorses a research model that brackets, at least temporarily, many of the current industry concerns with the practical usability of newsroom analysis .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885769193&doi=10.1177%2f1461444812465137&partnerID=40&md5=a20bafd34c1504f04f5c8bdb72857f46', 'citations': 181, 'keywords': ['Computational journalism', 'culture', 'data', 'digital humanities', 'ethnography', 'journalism', 'news institutionalism', 'political economy']}\n",
            "3: {'doi': '10.1007/s10994-013-5413-0', 'title': 'Interactive topic modeling', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': ' Topic models are a useful and ubiquitous tool for understanding large corpora. For many users in computational social science, digital humanities, and information studies - who are not machine learning experts - existing models and frameworks are often a \"take it or leave it\" proposition. This paper presents a mechanism for giving users a voice by encoding users\\' feedback to topic models.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': \" Topic models are useful and ubiquitous tool for understanding large corpora, but topic models are not perfect . This paper presents a mechanism for giving users a voice by encoding users' feedback to topic models as correlations between words into a topic model . This framework, interactive topic modeling (itm), allows untrained users to encode their feedback easily and iteratively into the topic models .\"}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'Topic models are useful tool for understanding large corpora, but not perfect. Interactive topic modeling allows untrained users to encode their feedback easily and iteratively into the topic models. The paper developed more efficient inference algorithms for tree-based topic models and validated the framework with simulated and real users.'}, {'model': 'google/pegasus-large', 'summarized_text': 'This framework, interactive topic modeling (itm), allows untrained users to encode their feedback easily and iteratively into the topic models.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'We develop more efficient inference algorithms for tree-based topic models . We validate the framework both with simulated and real users .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901496744&doi=10.1007%2fs10994-013-5413-0&partnerID=40&md5=5e9f7ce6d9daf635fb278501a9243d93', 'citations': 144, 'keywords': ['Feedback', 'Gibbs sampling', 'Interactive topic modeling', 'Latent Dirichlet Allocation', 'Online learning', 'Topic models']}\n",
            "4: {'doi': '10.1108/00220411111109449', 'title': 'Enabled backchannel: conference Twitter use by digital humanists', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'Few studies have been undertaken to make explicit how microblogging technologies are used by and can benefit scholars. This paper considers the use of Twitter as a digital backchannel by the Digital Humanities (DH) community. The resulting archive of 4,574 “Tweets” was analysed using various quantitative and qualitative methods.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': ' Few studies have been undertaken to make explicit how microblogging technologies are used by and can benefit scholars . This paper considers the use of Twitter as a digital backchannel by the Digital Humanities (DH) community . The analysis revealed the close-knit nature of the DH researcher community, which may be somewhat intimidating for those new to the field or conference .'}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'This paper considers the use of Twitter as a digital backchannel by the Digital Humanities community at three international 2009 conferences. The archive of 4,574 Tweets was analysed using various quantitative and qualitative methods. The analysis revealed the close-knit nature of the DH researcher community.'}, {'model': 'google/pegasus-large', 'summarized_text': 'This paper aims to investigate the use of Twitter by an academic community in various conference settings, and to pose the following questions: Does the use of a Twitterenabled backchannel enhance the conference experience, collaboration and the coconstruction of knowledge? Design/methodology/approach This paper considers the use of Twitter as a digital backchannel by the Digital Humanities (DH) community, taking as its focus postings to Twitter during three different international 2009 conferences. In this paper, a method has been suggested to categorise Tweets using open coded analysis to facilitate understanding of Tweetbased corpora, which could be adopted elsewhere.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': \"This paper aims to investigate the use of Twitter by an academic community in various conference settings . The archive of 4,574 'Tweets' was analysed using various quantitative and qualitative methods . The analysis revealed the closeknit nature of the DH researcher community, which may be somewhat intimidating for those new to the field or conference .\"}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952292203&doi=10.1108%2f00220411111109449&partnerID=40&md5=63335e5ffd7293ab3b3c3a465d083c7a', 'citations': 144, 'keywords': ['Conferences', 'Digital communication systems', 'Social networks', 'User studies']}\n",
            "5: {'doi': '10.1108/AJIM-09-2013-0094', 'title': 'Programmed method: Developing a toolset for capturing and analyzing tweets', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'Digital Methods Initiative Twitter Capture and Analysis Toolset is a toolset for capturing and analyzing Twitter data. The authors aim at situating the development of the toolset in relation to methodological debates in the social sciences and humanities. The software provides robust and reproducible data capture and analysis, and interlinks with existing analytical software.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': ' Digital Methods Initiative Twitter Capture and Analysis Toolset is a toolset for capturing and analyzing Twitter data . The authors argue that the type of data used for, as well as the methods encoded in, computational systems have epistemological repercussions for research . They aim at situating the development of the toolset in relation to methodological debates in the social sciences and humanities .'}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'Digital Methods Initiative Twitter Capture and Analysis Toolset is a toolset for capturing and analyzing Twitter data. The design of the software is inspired by exchanges and debates with scholars from a variety of disciplines. The aim is to keep computational work open for various epistemic sensibilities.'}, {'model': 'google/pegasus-large', 'summarized_text': 'Design/methodology/approach–The authors review the possibilities and limitations of existing approaches to capture and analyze Twitter data in order to address the various ways in which computational systems frame research.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'The purpose of this paper is to introduce Digital Methods Initiative Twitter Capture and Analysis Toolset, a toolset for capturing and analyzing Twitter data . The authors aim at situating the development of the toolset in relation to methodological debates in the social sciences and humanities .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928249663&doi=10.1108%2fAJIM-09-2013-0094&partnerID=40&md5=503326daa805093e265cece8d666ac3d', 'citations': 143, 'keywords': ['Analysis', 'Computational social science', 'Data collection', 'Digital humanities', 'Digital methods', 'Twitter']}\n",
            "6: {'doi': '10.32614/rj-2016-007', 'title': 'Stylometry with R: A package for computational text analysis', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'Stylometry (computational stylistics) is concerned with the quantitative study of writing style. Stylo provides an attractive graphical user interface for high-level exploratory analyses. It is especially suited for an audience of novices, without programming skills (e.g. from the Digital Humanities)'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': \" This software paper describes 'Stylometry with R' (stylo), a flexible R package for the highlevel analysis of writing style in stylometry . Stylometry (computational stylistics) is concerned with the quantitative study of . writing style, e.g. authorship verification . This application has considerable potential in forensic contexts, as well as historical research .\"}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'Stylometry with R (stylo) is a flexible R package for the high level analysis of writing style in stylometry. Stylometry (computational stylistics) is concerned with the quantitative study of the writing style. It has potential in forensic contexts, as well as historical research.'}, {'model': 'google/pegasus-large', 'summarized_text': \"This software paper describes 'Stylometry with R' (stylo), a flexible R package for the highlevel analysis of writing style in stylometry.\"}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': \"'Stylometry with R' (stylo) is a flexible R package for the highlevel analysis of writing style in stylometry . Stylometry (computational stylistics) is concerned with the quantitative study of writing style .\"}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010281284&doi=10.32614%2frj-2016-007&partnerID=40&md5=7bc156d9c817b635cf13a9dd554f5ba3', 'citations': 134, 'keywords': []}\n",
            "7: {'doi': '10.1080/01916599.2012.714635', 'title': \"What's the Big Idea? Intellectual History and the Longue Durée\", 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'Historians of all kinds are beginning to return to temporally expansive studies. What are the reasons for this revival of long-range intellectual history? And how might it be rendered methodologically robust as well as historically compelling? This article proposes a model of transtemporal history, proceeding via serial contextualism.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': ' Historians of all kinds are beginning to return to temporally expansive studies after decades of aversion and neglect . This article proposes a model of transtemporal history, proceeding via serial contextualism to create a history in ideas spanning centuries, even millennia . Key examples come from work in progress on ideas of civil war from ancient Rome to the present .'}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'There are signs that historians are returning to long-range intellectual history. This article proposes a model of transtemporal history, proceeding via serial contextualism to create a history in ideas spanning centuries and millennia. The article concludes with reflections on the potential impact of the digital humanities on the practice of long-distance history.'}, {'model': 'google/pegasus-large', 'summarized_text': 'The article concludes with brief reflections on the potential impact of the digital humanities on the practice of long-range intellectual history.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'Historians of all kinds are returning to temporally expansive studies after decades of aversion and neglect . This article proposes a model of transtemporal history, proceeding via serial contextualism to create a history in ideas spanning centuries, even millennia .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868280635&doi=10.1080%2f01916599.2012.714635&partnerID=40&md5=3b5e264dcffa6a16aad5f2d68dfad625', 'citations': 109, 'keywords': ['Cambridge School', 'civil war', 'conceptual history', 'digital humanities', 'longue durée']}\n",
            "8: {'doi': '10.1111/j.1475-5661.2010.00405.x', 'title': 'Mapping the English Lake District: A literary GIS', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': \"This paper expands the conceptual possibilities opened up by the use of GIS technology through an exploration of the theoretical potentiality of literary GIS. Drawing on work carried out as part of an interdisciplinary project, 'Mapping the Lakes', the paper focuses on the ways in which GIS can be used to explore the spatial relationships between two textual accounts of tours.\"}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': \" This paper expands the conceptual possibilities opened up by the use of GIS technology through an exploration of the theoretical potentiality of literary GIS . Drawing on work carried out as part of an interdisciplinary project, 'Mapping the Lakes', the paper focuses on the ways in which GIS can be used to explore the spatial relationships between two textual accounts of tours of the English Lake District .\"}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': \"This paper explores the theoretical potentiality of literary GIS. It is based on work carried out as part of an interdisciplinary project, 'Mapping the Lakes'. The paper focuses on the spatial relationships between two textual accounts of tours of the English Lake District: Thomas Gray's in the autumn of 1769 and Samuel Taylor Coleridge's in August 1802.\"}, {'model': 'google/pegasus-large', 'summarized_text': 'Alongside this text-specific focus, the paper also draws on recent spatial literary criticism to reflect, more generally, on the critical possibilities and problems associated with the digital mapping of space and place in literature.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'This paper expands the conceptual possibilities opened up by the use of GIS technology . It focuses on the ways in which GIS can be used to explore the spatial relationships between two textual accounts of tours of the English Lake District . Ultimately, the paper seeks to open up methodological and critical space for the ongoing development of literary GIS .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649784112&doi=10.1111%2fj.1475-5661.2010.00405.x&partnerID=40&md5=a49abb3528b15ede2dd5067792dd83e5', 'citations': 93, 'keywords': ['Digital humanities', 'English Lake District', 'GIS', 'Literary cartography', 'Literary studies', 'Spatial theory']}\n",
            "9: {'doi': '10.1177/0309132512444063', 'title': 'Crossing the qualitative- quantitative divide II: Inventive approaches to big data, mobile methods, and rhythmanalysis', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'In this second of three reports on qualitative and quantitative methods we highlight novel methods with particular purchase on the problems of our time. We again focus on scholarship crossing multiple geographical divides, those of neo/paleo geography, qualitative/quantitative methods, and physical/human geography. We do so now by concentrating on three areas: the emerging digital humanities and the rise of big data.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': ' In this second of three reports on qualitative and quantitative methods we highlight novel methods with particular purchase on the problems of our time . We again focus on scholarship crossing multiple geographical divides, those of neo/paleo geography, qualitative/quantitative methods, and physical/human geography . With this broad approach we seek also to encourage consilience, synergy, and a positive embrace of diversity in geographical scholarship .'}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'In the second of three reports on qualitative and quantitative methods we highlight novel methods with particular purchase on the problems of our time. We focus on scholarship crossing multiple geographical divides, those of neo/paleo geography, qualitative/quantitative methods, and physical/human geography.'}, {'model': 'google/pegasus-large', 'summarized_text': 'We again focus on scholarship crossing multiple geographical divides, those of neo/paleo geography, qualitative/quantitative methods, and physical/human geography.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'In this second of three reports on qualitative and quantitative methods we highlight novel methods . We aim to encourage consilience, synergy and a positive embrace of diversity in geographical scholarship .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875024343&doi=10.1177%2f0309132512444063&partnerID=40&md5=515741df9a331ef610192a73dfcc8080', 'citations': 89, 'keywords': ['big data', 'digital humanities', 'inventive methods', 'methodology', 'mobile methods', 'mobilities', 'qualitative', 'quantitative']}\n"
          ]
        }
      ],
      "source": [
        "print('Summarized Papers:')\n",
        "for i in range(0,10,1):\n",
        "  print(str(i) + ': ' + str(list_papers_summ[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stage 3: Save Current Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "json_dump = {\n",
        "    \"top_10_papers\": top_10_papers,\n",
        "    \"top_10_authors\": top_10_authors,\n",
        "    \"top_10_keywords\": top_10_keywords,\n",
        "    \"summaries\": list_papers_summ\n",
        "}\n",
        "\n",
        "with open(\"/home/dxmonteiro/Desktop/WORKSPACE/ProfExtra/output/1stdump.json\", \"w\") as outfile:\n",
        "    outfile.write(str(json_dump))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stage 4: Extracting Keywords with AutoModels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4.1. Reload file data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = open('/home/dxmonteiro/Desktop/WORKSPACE/ProfExtra/output/1stdump.json')\n",
        "processed_data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'top_10_papers': [{'doi': '10.1177/2053951714528481', 'title': 'Big Data, new epistemologies and paradigm shifts', 'abstract': 'This article examines how the availability of Big Data, coupled with new data analytics, challenges established epistemologies across the sciences, social sciences and humanities, and assesses the extent to which they are engendering paradigm shifts across multiple disciplines. In particular, it critically explores new forms of empiricism that declare ‘the end of theory’, the creation of data-driven rather than knowledge-driven science, and the development of digital humanities and computational social sciences that propose radically different ways to make sense of culture, history, economy and society. It is argued that: (1) Big Data and new data analytics are disruptive innovations which are reconfiguring in many instances how research is conducted; and (2) there is an urgent need for wider critical reflection within the academy on the epistemological implications of the unfolding data revolution, a task that has barely begun to be tackled despite the rapid changes in research practices presently taking place. After critically reviewing emerging epistemological positions, it is contended that a potentially fruitful approach would be the development of a situated, reflexive and contextually nuanced epistemology. © The Author(s) 2014 Reprints and permissions: sagepub.co.uk/journalsPermissions.nav.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073682542&doi=10.1177%2f2053951714528481&partnerID=40&md5=49cbcd64a939cb47af2f8996d0c114a2', 'citations': 1062, 'keywords': ['Big Data', 'computational social sciences', 'data analytics', 'data-driven science', 'digital humanities', 'end of theory', 'epistemology', 'paradigms'], 'authors': ['Kitchin R.']}, {'doi': '10.1007/s11192-014-1229-3', 'title': 'Disciplinary differences in Twitter scholarly communication', 'abstract': 'This paper investigates disciplinary differences in how researchers use the microblogging site Twitter. Tweets from selected researchers in ten disciplines (astrophysics, biochemistry, digital humanities, economics, history of science, cheminformatics, cognitive science, drug discovery, social network analysis, and sociology) were collected and analyzed both statistically and qualitatively. The researchers tended to share more links and retweet more than the average Twitter users in earlier research and there were clear disciplinary differences in how they used Twitter. Biochemists retweeted substantially more than researchers in the other disciplines. Researchers in digital humanities and cognitive science used Twitter more for conversations, while researchers in economics shared the most links. Finally, whilst researchers in biochemistry, astrophysics, cheminformatics and digital humanities seemed to use Twitter for scholarly communication, scientific use of Twitter in economics, sociology and history of science appeared to be marginal. © 2014, Akadémiai Kiadó, Budapest, Hungary.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892447024&doi=10.1007%2fs11192-014-1229-3&partnerID=40&md5=0f4e0be141475ec6e96b15cb15d1be9c', 'citations': 182, 'keywords': ['Altmetrics', 'Disciplinary differences', 'Scholarly communication', 'Twitter', 'Webometrics'], 'authors': ['Holmberg K.', 'Thelwall M.']}, {'doi': '10.1177/1461444812465137', 'title': 'Towards a sociology of computational and algorithmic journalism', 'abstract': 'This article advances a sociological approach to computational journalism. By \"computational journalism\" the article refers to the increasingly ubiquitous forms of algorithmic, social scientific, and mathematical forms of newswork adopted by many 21st-century newsrooms and touted by many educational institutions as \"the future of news.\" By \"sociological approach,\" the article endorses a research model that brackets, at least temporarily, many of the current industry concerns with the practical usability of newsroom analysis. The bulk of the article outlines a series of six lenses through which such an approach to computational journalism might be carried out. Four of these lenses are drawn from Schudson\\'s classic typology of the sociology of news-economic, political, cultural, and organizational approaches. In addition, the author adds Bordieuean field approaches and technological lenses to the mix. In each instance, the author discusses how particular approaches might need to be modified in order to study computational journalism in the digital age. © The Author(s) 2012.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885769193&doi=10.1177%2f1461444812465137&partnerID=40&md5=a20bafd34c1504f04f5c8bdb72857f46', 'citations': 181, 'keywords': ['Computational journalism', 'culture', 'data', 'digital humanities', 'ethnography', 'journalism', 'news institutionalism', 'political economy'], 'authors': ['Anderson C.W.']}, {'doi': '10.1007/s10994-013-5413-0', 'title': 'Interactive topic modeling', 'abstract': 'Topic models are a useful and ubiquitous tool for understanding large corpora. However, topic models are not perfect, and for many users in computational social science, digital humanities, and information studies - who are not machine learning experts - existing models and frameworks are often a \"take it or leave it\" proposition. This paper presents a mechanism for giving users a voice by encoding users\\' feedback to topic models as correlations between words into a topic model. This framework, interactive topic modeling (itm), allows untrained users to encode their feedback easily and iteratively into the topic models. Because latency in interactive systems is crucial, we develop more efficient inference algorithms for tree-based topic models. We validate the framework both with simulated and real users. © 2013 The Author(s).', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901496744&doi=10.1007%2fs10994-013-5413-0&partnerID=40&md5=5e9f7ce6d9daf635fb278501a9243d93', 'citations': 144, 'keywords': ['Feedback', 'Gibbs sampling', 'Interactive topic modeling', 'Latent Dirichlet Allocation', 'Online learning', 'Topic models'], 'authors': ['Hu Y.', 'Boyd-Graber J.', 'Satinoff B.', 'Smith A.']}, {'doi': '10.1108/00220411111109449', 'title': 'Enabled backchannel: conference Twitter use by digital humanists', 'abstract': \"Purpose – To date, few studies have been undertaken to make explicit how microblogging technologies are used by and can benefit scholars. This paper aims to investigate the use of Twitter by an academic community in various conference settings, and to pose the following questions: Does the use of a Twitter\\ue4f8enabled backchannel enhance the conference experience, collaboration and the co\\ue4f8construction of knowledge? and How is microblogging used within academic conferences, and can one articulate the benefits it may bring to a discipline? Design/methodology/approach This paper considers the use of Twitter as a digital backchannel by the Digital Humanities (DH) community, taking as its focus postings to Twitter during three different international 2009 conferences. The resulting archive of 4,574 “Tweets” was analysed using various quantitative and qualitative methods, including a qualitative categorisation of Twitter posts by open coded analysis, a quantitative examination of user conventions, and text analysis tools. Prominent Tweeters were identified and a small qualitative survey was undertaken to ascertain individuals' attitudes towards a Twitter\\ue4f8enabled backchannel. Findings – Conference hashtagged Twitter activity does not constitute a single distributed conversation, but rather multiple monologues with a few intermittent, discontinuous, loosely joined dialogues between users. The digital backchannel constitutes a multidirectional complex space in which the users make notes, share resources, hold discussions and ask questions as well as establishing a clear individual online presence. The use of Twitter as a conference platform enables the community to expand communication and participation in events amongst its members. The analysis revealed the close\\ue4f8knit nature of the DH researcher community, which may be somewhat intimidating for those new to the field or conference. Practical implications This study has indicated that, given that Twitter is becoming increasingly important for academic communities, new, dedicated methodologies for the analysis and understanding of Tweet\\ue4f8based corpora are necessary. Routinely used textual analysis tools cannot be applied to corpora of Tweets in a straightforward manner, due to the creative and fragmentary nature of language used within microblogging. In this paper, a method has been suggested to categorise Tweets using open coded analysis to facilitate understanding of Tweet\\ue4f8based corpora, which could be adopted elsewhere. Originality/value – This paper is the first known exhaustive study that concentrates on how microblogging technologies such as Twitter are used by and can benefit scholars. This data set both provides a valuable insight into the prevalence of a variety of Twitter practices within the constraints of a conference setting, and highlights the need for methodologies to be developed to analyse social media streams such as Twitter feeds. It also provides a bibliography of other research into microblogging. © 2011, Emerald Group Publishing Limited\", 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952292203&doi=10.1108%2f00220411111109449&partnerID=40&md5=63335e5ffd7293ab3b3c3a465d083c7a', 'citations': 144, 'keywords': ['Conferences', 'Digital communication systems', 'Social networks', 'User studies'], 'authors': ['Ross C.', 'Terras M.', 'Warwick C.', 'Welsh A.']}, {'doi': '10.1108/AJIM-09-2013-0094', 'title': 'Programmed method: Developing a toolset for capturing and analyzing tweets', 'abstract': 'Purpose–The purpose of this paper is to introduce Digital Methods Initiative Twitter Capture and Analysis Toolset, a toolset for capturing and analyzing Twitter data. Instead of just presenting a technical paper detailing the system, however, the authors argue that the type of data used for, as well as the methods encoded in, computational systems have epistemological repercussions for research. The authors thus aim at situating the development of the toolset in relation to methodological debates in the social sciences and humanities. Design/methodology/approach–The authors review the possibilities and limitations of existing approaches to capture and analyze Twitter data in order to address the various ways in which computational systems frame research. The authors then introduce the open-source toolset and put forward an approach that embraces methodological diversity and epistemological plurality. Findings–The authors find that design decisions and more general methodological reasoning can and should go hand in hand when building tools for computational social science or digital humanities. Practical implications–Besides methodological transparency, the software provides robust and reproducible data capture and analysis, and interlinks with existing analytical software. Epistemic plurality is emphasized by taking into account how Twitter structures information, by allowing for a number of different sampling techniques, by enabling a variety of analytical approaches or paradigms, and by facilitating work at the micro, meso, and macro levels. Originality/value–The paper opens up critical debate by connecting tool design to fundamental interrogations of methodology and its repercussions for the production of knowledge. The design of the software is inspired by exchanges and debates with scholars from a variety of disciplines and the attempt to propose a flexible and extensible tool that accommodates a wide array of methodological approaches is directly motivated by the desire to keep computational work open for various epistemic sensibilities. © Emerald Group Publishing Limited.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928249663&doi=10.1108%2fAJIM-09-2013-0094&partnerID=40&md5=503326daa805093e265cece8d666ac3d', 'citations': 143, 'keywords': ['Analysis', 'Computational social science', 'Data collection', 'Digital humanities', 'Digital methods', 'Twitter'], 'authors': ['Borra E.', 'Rieder B.']}, {'doi': '10.32614/rj-2016-007', 'title': 'Stylometry with R: A package for computational text analysis', 'abstract': \"This software paper describes 'Stylometry with R' (stylo), a flexible R package for the highlevel analysis of writing style in stylometry. Stylometry (computational stylistics) is concerned with the quantitative study of writing style, e.g. authorship verification, an application which has considerable potential in forensic contexts, as well as historical research. In this paper we introduce the possibilities of stylo for computational text analysis, via a number of dummy case studies from English and French literature. We demonstrate how the package is particularly useful in the exploratory statistical analysis of texts, e.g. with respect to authorial writing style. Because stylo provides an attractive graphical user interface for high-level exploratory analyses, it is especially suited for an audience of novices, without programming skills (e.g. from the Digital Humanities). More experienced users can benefit from our implementation of a series of standard pipelines for text processing, as well as a number of similarity metrics.\", 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010281284&doi=10.32614%2frj-2016-007&partnerID=40&md5=7bc156d9c817b635cf13a9dd554f5ba3', 'citations': 134, 'keywords': [], 'authors': ['Eder M.', 'Rybicki J.', 'Kestemont M.']}, {'doi': '10.1080/01916599.2012.714635', 'title': \"What's the Big Idea? Intellectual History and the Longue Durée\", 'abstract': 'Historians of all kinds are beginning to return to temporally expansive studies after decades of aversion and neglect. There are even signs that intellectual historians are returning to the longue durée. What are the reasons for this revival of long-range intellectual history? And how might it be rendered methodologically robust as well as historically compelling? This article proposes a model of transtemporal history, proceeding via serial contextualism to create a history in ideas spanning centuries, even millennia: key examples come from work in progress on ideas of civil war from ancient Rome to the present. The article concludes with brief reflections on the potential impact of the digital humanities on the practice of long-range intellectual history. © 2012 Copyright Taylor and Francis Group, LLC.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868280635&doi=10.1080%2f01916599.2012.714635&partnerID=40&md5=3b5e264dcffa6a16aad5f2d68dfad625', 'citations': 109, 'keywords': ['Cambridge School', 'civil war', 'conceptual history', 'digital humanities', 'longue durée'], 'authors': ['Armitage D.']}, {'doi': '10.1111/j.1475-5661.2010.00405.x', 'title': 'Mapping the English Lake District: A literary GIS', 'abstract': \"To date, much of the work that uses Geographical Information Systems (GIS) to study human geographies applies a social science paradigm to quantitative data. There is a growing recognition of the need, however, to test whether GIS can be used to map out the qualitative 'data' provided by the articulation of subjective spatial experiences. This paper expands the conceptual possibilities opened up by the use of GIS technology through an exploration of the theoretical potentiality of literary GIS. Drawing on work carried out as part of an interdisciplinary project, 'Mapping the Lakes', the paper focuses on the ways in which GIS can be used to explore the spatial relationships between two textual accounts of tours of the English Lake District: the proto-Picturesque journey undertaken by the poet, Thomas Gray, in the autumn of 1769; and Samuel Taylor Coleridge's self-consciously post-Picturesque 'circumcursion' of August 1802. Alongside this text-specific focus, the paper also draws on recent spatial literary criticism to reflect, more generally, on the critical possibilities and problems associated with the digital mapping of space and place in literature. Ultimately, the paper seeks to open up methodological and critical space for the ongoing development of literary GIS. © 2010 The Authors. Transactions of the Institute of British Geographers © 2010 Royal Geographical Society (with the Institute of British Geographers).\", 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649784112&doi=10.1111%2fj.1475-5661.2010.00405.x&partnerID=40&md5=a49abb3528b15ede2dd5067792dd83e5', 'citations': 93, 'keywords': ['Digital humanities', 'English Lake District', 'GIS', 'Literary cartography', 'Literary studies', 'Spatial theory'], 'authors': ['Cooper D.', 'Gregory I.N.']}, {'doi': '10.1177/0309132512444063', 'title': 'Crossing the qualitative- quantitative divide II: Inventive approaches to big data, mobile methods, and rhythmanalysis', 'abstract': 'In this second of three reports on qualitative and quantitative methods we highlight novel methods with particular purchase on the problems of our time. We again focus on scholarship crossing multiple geographical divides, those of neo/paleo geography, qualitative/quantitative methods, and physical/human geography. We do so now by concentrating on three areas: the emerging digital humanities and the rise of big data, mobile methods, and rhythmanalysis. With this broad approach we seek also to encourage consilience, synergy, and a positive embrace of diversity in geographical scholarship. © The Author(s) 2012.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875024343&doi=10.1177%2f0309132512444063&partnerID=40&md5=515741df9a331ef610192a73dfcc8080', 'citations': 89, 'keywords': ['big data', 'digital humanities', 'inventive methods', 'methodology', 'mobile methods', 'mobilities', 'qualitative', 'quantitative'], 'authors': ['DeLyser D.', 'Sui D.']}], 'top_10_authors': [{'name': 'Kitchin R.', 'frequence': 1, 'citations': 1062}, {'name': 'Terras M.', 'frequence': 8, 'citations': 218}, {'name': 'Warwick C.', 'frequence': 5, 'citations': 191}, {'name': 'Holmberg K.', 'frequence': 1, 'citations': 182}, {'name': 'Thelwall M.', 'frequence': 1, 'citations': 182}, {'name': 'Anderson C.W.', 'frequence': 1, 'citations': 181}, {'name': 'Welsh A.', 'frequence': 3, 'citations': 154}, {'name': 'Kestemont M.', 'frequence': 5, 'citations': 147}, {'name': 'Hu Y.', 'frequence': 1, 'citations': 144}, {'name': 'Boyd-Graber J.', 'frequence': 1, 'citations': 144}], 'top_10_keywords': [{'name': 'Digital humanities', 'frequence': 593, 'citations': 2692}, {'name': 'Florence', 'frequence': 1, 'citations': 0}, {'name': 'LiDAR', 'frequence': 1, 'citations': 0}, {'name': 'Model', 'frequence': 1, 'citations': 0}, {'name': 'Orsanmichele', 'frequence': 1, 'citations': 0}, {'name': 'Photogrammetry', 'frequence': 3, 'citations': 1}, {'name': 'Potree', 'frequence': 1, 'citations': 0}, {'name': 'Scan', 'frequence': 1, 'citations': 0}, {'name': '3D technologies', 'frequence': 1, 'citations': 0}, {'name': 'Archaeology', 'frequence': 12, 'citations': 30}], 'summaries': [{'doi': '10.1177/2053951714528481', 'title': 'Big Data, new epistemologies and paradigm shifts', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'This article examines how the availability of Big Data, coupled with new data analytics, challenges established epistemologies across the sciences, social sciences and humanities. In particular, it critically explores new forms of empiricism that declare ‘the end of theory’ and the creation of data-driven rather than knowledge-driven science.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': ' This article examines how the availability of Big Data, coupled with new data analytics, challenges established epistemologies across the sciences, social sciences and humanities . In particular, it critically explores new forms of empiricism that declare ‘the end of theory’ and the creation of data-driven rather than knowledge-driven science .'}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'Big Data and new data analytics are disruptive innovations which are reconfiguring in many instances how research is conducted. There is an urgent need for a critical reflection within the academy on the epistemological implications of the unfolding data revolution. A potentially fruitful approach would be the development of a situated, reflexive and contextually nuanced epistemology.'}, {'model': 'google/pegasus-large', 'summarized_text': 'This article examines how the availability of Big Data, coupled with new data analytics, challenges established epistemologies across the sciences, social sciences and humanities, and assesses the extent to which they are engendering paradigm shifts across multiple disciplines.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'The availability of Big Data and new data analytics challenges established epistemologies across the sciences, social sciences and humanities . It assesses the extent to which they are engendering paradigm shifts across multiple disciplines .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073682542&doi=10.1177%2f2053951714528481&partnerID=40&md5=49cbcd64a939cb47af2f8996d0c114a2', 'citations': 1062, 'keywords': ['Big Data', 'computational social sciences', 'data analytics', 'data-driven science', 'digital humanities', 'end of theory', 'epistemology', 'paradigms']}, {'doi': '10.1007/s11192-014-1229-3', 'title': 'Disciplinary differences in Twitter scholarly communication', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'This paper investigates disciplinary differences in how researchers use the microblogging site Twitter. Tweets from selected researchers in ten disciplines were collected and analyzed both statistically and qualitatively. The researchers tended to share more links and retweet more than the average Twitter users in earlier research. Biochemists retweeted substantially more than researchers in the other disciplines.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': ' This paper investigates disciplinary differences in how researchers use Twitter . Tweets from selected researchers in ten disciplines were collected and analyzed both statistically and qualitatively . Biochemists retweeted substantially more than researchers in the other disciplines . Researchers in digital humanities and cognitive science used Twitter more for conversations, while researchers in economics shared the most links .'}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'This paper investigates disciplinary differences in how researchers use the microblogging site Twitter. Tweets from selected researchers in ten disciplines were collected and analyzed both statistically and qualitatively. The researchers tended to share more links and retweet more than the average Twitter user. Biochemists retweeted substantially more than researchers in the other disciplines. Researchers in digital humanities used Twitter more for conversations, while researchers in economics shared the most links.'}, {'model': 'google/pegasus-large', 'summarized_text': 'Finally, whilst researchers in biochemistry, astrophysics, cheminformatics and digital humanities seemed to use Twitter for scholarly communication, scientific use of Twitter in economics, sociology and history of science appeared to be marginal.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'The researchers tended to share more links and retweet more than the average Twitter users . Biochemists retweeted substantially more than researchers in the other disciplines .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892447024&doi=10.1007%2fs11192-014-1229-3&partnerID=40&md5=0f4e0be141475ec6e96b15cb15d1be9c', 'citations': 182, 'keywords': ['Altmetrics', 'Disciplinary differences', 'Scholarly communication', 'Twitter', 'Webometrics']}, {'doi': '10.1177/1461444812465137', 'title': 'Towards a sociology of computational and algorithmic journalism', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'This article advances a sociological approach to computational journalism. By \"computational journalism\" the article refers to the increasingly ubiquitous forms of algorithmic, social scientific, and mathematical forms of newswork. Four of these lenses are drawn from Schudson\\'s classic typology of the sociology of news-economic, political, cultural, and organizational approaches. In addition, the author adds Bordieuean field approaches and technological lenses to the mix.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': \" This article advances a sociological approach to computational journalism . The bulk of the article outlines a series of six lenses through which such an approach might be carried out . Four of these lenses are drawn from Schudson's classic typology of the sociology of news-economic, political, cultural, and organizational approaches . In each instance, the author discusses how particular approaches might need to be modified .\"}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': \"This article advances a sociological approach to computational journalism. Four of the lenses are drawn from Schudson's classic typology of the sociology of news-economic, political, cultural, and organizational approaches. The author adds Bordieuean field approaches and technological lenses to the mix.\"}, {'model': 'google/pegasus-large', 'summarized_text': 'The bulk of the article outlines a series of six lenses through which such an approach to computational journalism might be carried out.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'The article refers to increasingly ubiquitous forms of algorithmic, social scientific, and mathematical forms of newswork adopted by many 21st-century newsrooms . The article endorses a research model that brackets, at least temporarily, many of the current industry concerns with the practical usability of newsroom analysis .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885769193&doi=10.1177%2f1461444812465137&partnerID=40&md5=a20bafd34c1504f04f5c8bdb72857f46', 'citations': 181, 'keywords': ['Computational journalism', 'culture', 'data', 'digital humanities', 'ethnography', 'journalism', 'news institutionalism', 'political economy']}, {'doi': '10.1007/s10994-013-5413-0', 'title': 'Interactive topic modeling', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': ' Topic models are a useful and ubiquitous tool for understanding large corpora. For many users in computational social science, digital humanities, and information studies - who are not machine learning experts - existing models and frameworks are often a \"take it or leave it\" proposition. This paper presents a mechanism for giving users a voice by encoding users\\' feedback to topic models.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': \" Topic models are useful and ubiquitous tool for understanding large corpora, but topic models are not perfect . This paper presents a mechanism for giving users a voice by encoding users' feedback to topic models as correlations between words into a topic model . This framework, interactive topic modeling (itm), allows untrained users to encode their feedback easily and iteratively into the topic models .\"}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'Topic models are useful tool for understanding large corpora, but not perfect. Interactive topic modeling allows untrained users to encode their feedback easily and iteratively into the topic models. The paper developed more efficient inference algorithms for tree-based topic models and validated the framework with simulated and real users.'}, {'model': 'google/pegasus-large', 'summarized_text': 'This framework, interactive topic modeling (itm), allows untrained users to encode their feedback easily and iteratively into the topic models.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'We develop more efficient inference algorithms for tree-based topic models . We validate the framework both with simulated and real users .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901496744&doi=10.1007%2fs10994-013-5413-0&partnerID=40&md5=5e9f7ce6d9daf635fb278501a9243d93', 'citations': 144, 'keywords': ['Feedback', 'Gibbs sampling', 'Interactive topic modeling', 'Latent Dirichlet Allocation', 'Online learning', 'Topic models']}, {'doi': '10.1108/00220411111109449', 'title': 'Enabled backchannel: conference Twitter use by digital humanists', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'Few studies have been undertaken to make explicit how microblogging technologies are used by and can benefit scholars. This paper considers the use of Twitter as a digital backchannel by the Digital Humanities (DH) community. The resulting archive of 4,574 “Tweets” was analysed using various quantitative and qualitative methods.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': ' Few studies have been undertaken to make explicit how microblogging technologies are used by and can benefit scholars . This paper considers the use of Twitter as a digital backchannel by the Digital Humanities (DH) community . The analysis revealed the close-knit nature of the DH researcher community, which may be somewhat intimidating for those new to the field or conference .'}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'This paper considers the use of Twitter as a digital backchannel by the Digital Humanities community at three international 2009 conferences. The archive of 4,574 Tweets was analysed using various quantitative and qualitative methods. The analysis revealed the close-knit nature of the DH researcher community.'}, {'model': 'google/pegasus-large', 'summarized_text': 'This paper aims to investigate the use of Twitter by an academic community in various conference settings, and to pose the following questions: Does the use of a Twitterenabled backchannel enhance the conference experience, collaboration and the coconstruction of knowledge? Design/methodology/approach This paper considers the use of Twitter as a digital backchannel by the Digital Humanities (DH) community, taking as its focus postings to Twitter during three different international 2009 conferences. In this paper, a method has been suggested to categorise Tweets using open coded analysis to facilitate understanding of Tweetbased corpora, which could be adopted elsewhere.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': \"This paper aims to investigate the use of Twitter by an academic community in various conference settings . The archive of 4,574 'Tweets' was analysed using various quantitative and qualitative methods . The analysis revealed the closeknit nature of the DH researcher community, which may be somewhat intimidating for those new to the field or conference .\"}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952292203&doi=10.1108%2f00220411111109449&partnerID=40&md5=63335e5ffd7293ab3b3c3a465d083c7a', 'citations': 144, 'keywords': ['Conferences', 'Digital communication systems', 'Social networks', 'User studies']}, {'doi': '10.1108/AJIM-09-2013-0094', 'title': 'Programmed method: Developing a toolset for capturing and analyzing tweets', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'Digital Methods Initiative Twitter Capture and Analysis Toolset is a toolset for capturing and analyzing Twitter data. The authors aim at situating the development of the toolset in relation to methodological debates in the social sciences and humanities. The software provides robust and reproducible data capture and analysis, and interlinks with existing analytical software.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': ' Digital Methods Initiative Twitter Capture and Analysis Toolset is a toolset for capturing and analyzing Twitter data . The authors argue that the type of data used for, as well as the methods encoded in, computational systems have epistemological repercussions for research . They aim at situating the development of the toolset in relation to methodological debates in the social sciences and humanities .'}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'Digital Methods Initiative Twitter Capture and Analysis Toolset is a toolset for capturing and analyzing Twitter data. The design of the software is inspired by exchanges and debates with scholars from a variety of disciplines. The aim is to keep computational work open for various epistemic sensibilities.'}, {'model': 'google/pegasus-large', 'summarized_text': 'Design/methodology/approach–The authors review the possibilities and limitations of existing approaches to capture and analyze Twitter data in order to address the various ways in which computational systems frame research.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'The purpose of this paper is to introduce Digital Methods Initiative Twitter Capture and Analysis Toolset, a toolset for capturing and analyzing Twitter data . The authors aim at situating the development of the toolset in relation to methodological debates in the social sciences and humanities .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928249663&doi=10.1108%2fAJIM-09-2013-0094&partnerID=40&md5=503326daa805093e265cece8d666ac3d', 'citations': 143, 'keywords': ['Analysis', 'Computational social science', 'Data collection', 'Digital humanities', 'Digital methods', 'Twitter']}, {'doi': '10.32614/rj-2016-007', 'title': 'Stylometry with R: A package for computational text analysis', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'Stylometry (computational stylistics) is concerned with the quantitative study of writing style. Stylo provides an attractive graphical user interface for high-level exploratory analyses. It is especially suited for an audience of novices, without programming skills (e.g. from the Digital Humanities)'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': \" This software paper describes 'Stylometry with R' (stylo), a flexible R package for the highlevel analysis of writing style in stylometry . Stylometry (computational stylistics) is concerned with the quantitative study of . writing style, e.g. authorship verification . This application has considerable potential in forensic contexts, as well as historical research .\"}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'Stylometry with R (stylo) is a flexible R package for the high level analysis of writing style in stylometry. Stylometry (computational stylistics) is concerned with the quantitative study of the writing style. It has potential in forensic contexts, as well as historical research.'}, {'model': 'google/pegasus-large', 'summarized_text': \"This software paper describes 'Stylometry with R' (stylo), a flexible R package for the highlevel analysis of writing style in stylometry.\"}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': \"'Stylometry with R' (stylo) is a flexible R package for the highlevel analysis of writing style in stylometry . Stylometry (computational stylistics) is concerned with the quantitative study of writing style .\"}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010281284&doi=10.32614%2frj-2016-007&partnerID=40&md5=7bc156d9c817b635cf13a9dd554f5ba3', 'citations': 134, 'keywords': []}, {'doi': '10.1080/01916599.2012.714635', 'title': \"What's the Big Idea? Intellectual History and the Longue Durée\", 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'Historians of all kinds are beginning to return to temporally expansive studies. What are the reasons for this revival of long-range intellectual history? And how might it be rendered methodologically robust as well as historically compelling? This article proposes a model of transtemporal history, proceeding via serial contextualism.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': ' Historians of all kinds are beginning to return to temporally expansive studies after decades of aversion and neglect . This article proposes a model of transtemporal history, proceeding via serial contextualism to create a history in ideas spanning centuries, even millennia . Key examples come from work in progress on ideas of civil war from ancient Rome to the present .'}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'There are signs that historians are returning to long-range intellectual history. This article proposes a model of transtemporal history, proceeding via serial contextualism to create a history in ideas spanning centuries and millennia. The article concludes with reflections on the potential impact of the digital humanities on the practice of long-distance history.'}, {'model': 'google/pegasus-large', 'summarized_text': 'The article concludes with brief reflections on the potential impact of the digital humanities on the practice of long-range intellectual history.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'Historians of all kinds are returning to temporally expansive studies after decades of aversion and neglect . This article proposes a model of transtemporal history, proceeding via serial contextualism to create a history in ideas spanning centuries, even millennia .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868280635&doi=10.1080%2f01916599.2012.714635&partnerID=40&md5=3b5e264dcffa6a16aad5f2d68dfad625', 'citations': 109, 'keywords': ['Cambridge School', 'civil war', 'conceptual history', 'digital humanities', 'longue durée']}, {'doi': '10.1111/j.1475-5661.2010.00405.x', 'title': 'Mapping the English Lake District: A literary GIS', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': \"This paper expands the conceptual possibilities opened up by the use of GIS technology through an exploration of the theoretical potentiality of literary GIS. Drawing on work carried out as part of an interdisciplinary project, 'Mapping the Lakes', the paper focuses on the ways in which GIS can be used to explore the spatial relationships between two textual accounts of tours.\"}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': \" This paper expands the conceptual possibilities opened up by the use of GIS technology through an exploration of the theoretical potentiality of literary GIS . Drawing on work carried out as part of an interdisciplinary project, 'Mapping the Lakes', the paper focuses on the ways in which GIS can be used to explore the spatial relationships between two textual accounts of tours of the English Lake District .\"}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': \"This paper explores the theoretical potentiality of literary GIS. It is based on work carried out as part of an interdisciplinary project, 'Mapping the Lakes'. The paper focuses on the spatial relationships between two textual accounts of tours of the English Lake District: Thomas Gray's in the autumn of 1769 and Samuel Taylor Coleridge's in August 1802.\"}, {'model': 'google/pegasus-large', 'summarized_text': 'Alongside this text-specific focus, the paper also draws on recent spatial literary criticism to reflect, more generally, on the critical possibilities and problems associated with the digital mapping of space and place in literature.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'This paper expands the conceptual possibilities opened up by the use of GIS technology . It focuses on the ways in which GIS can be used to explore the spatial relationships between two textual accounts of tours of the English Lake District . Ultimately, the paper seeks to open up methodological and critical space for the ongoing development of literary GIS .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649784112&doi=10.1111%2fj.1475-5661.2010.00405.x&partnerID=40&md5=a49abb3528b15ede2dd5067792dd83e5', 'citations': 93, 'keywords': ['Digital humanities', 'English Lake District', 'GIS', 'Literary cartography', 'Literary studies', 'Spatial theory']}, {'doi': '10.1177/0309132512444063', 'title': 'Crossing the qualitative- quantitative divide II: Inventive approaches to big data, mobile methods, and rhythmanalysis', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'In this second of three reports on qualitative and quantitative methods we highlight novel methods with particular purchase on the problems of our time. We again focus on scholarship crossing multiple geographical divides, those of neo/paleo geography, qualitative/quantitative methods, and physical/human geography. We do so now by concentrating on three areas: the emerging digital humanities and the rise of big data.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': ' In this second of three reports on qualitative and quantitative methods we highlight novel methods with particular purchase on the problems of our time . We again focus on scholarship crossing multiple geographical divides, those of neo/paleo geography, qualitative/quantitative methods, and physical/human geography . With this broad approach we seek also to encourage consilience, synergy, and a positive embrace of diversity in geographical scholarship .'}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'In the second of three reports on qualitative and quantitative methods we highlight novel methods with particular purchase on the problems of our time. We focus on scholarship crossing multiple geographical divides, those of neo/paleo geography, qualitative/quantitative methods, and physical/human geography.'}, {'model': 'google/pegasus-large', 'summarized_text': 'We again focus on scholarship crossing multiple geographical divides, those of neo/paleo geography, qualitative/quantitative methods, and physical/human geography.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'In this second of three reports on qualitative and quantitative methods we highlight novel methods . We aim to encourage consilience, synergy and a positive embrace of diversity in geographical scholarship .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875024343&doi=10.1177%2f0309132512444063&partnerID=40&md5=515741df9a331ef610192a73dfcc8080', 'citations': 89, 'keywords': ['big data', 'digital humanities', 'inventive methods', 'methodology', 'mobile methods', 'mobilities', 'qualitative', 'quantitative']}]}\n"
          ]
        }
      ],
      "source": [
        "print(processed_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4.2. Get top10_papers & top10_summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "processed_10papers = processed_data.get('top_10_papers')\n",
        "processed_10summaries = processed_data.get('summaries')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'doi': '10.1177/2053951714528481', 'title': 'Big Data, new epistemologies and paradigm shifts', 'abstract': 'This article examines how the availability of Big Data, coupled with new data analytics, challenges established epistemologies across the sciences, social sciences and humanities, and assesses the extent to which they are engendering paradigm shifts across multiple disciplines. In particular, it critically explores new forms of empiricism that declare ‘the end of theory’, the creation of data-driven rather than knowledge-driven science, and the development of digital humanities and computational social sciences that propose radically different ways to make sense of culture, history, economy and society. It is argued that: (1) Big Data and new data analytics are disruptive innovations which are reconfiguring in many instances how research is conducted; and (2) there is an urgent need for wider critical reflection within the academy on the epistemological implications of the unfolding data revolution, a task that has barely begun to be tackled despite the rapid changes in research practices presently taking place. After critically reviewing emerging epistemological positions, it is contended that a potentially fruitful approach would be the development of a situated, reflexive and contextually nuanced epistemology. © The Author(s) 2014 Reprints and permissions: sagepub.co.uk/journalsPermissions.nav.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073682542&doi=10.1177%2f2053951714528481&partnerID=40&md5=49cbcd64a939cb47af2f8996d0c114a2', 'citations': 1062, 'keywords': ['Big Data', 'computational social sciences', 'data analytics', 'data-driven science', 'digital humanities', 'end of theory', 'epistemology', 'paradigms'], 'authors': ['Kitchin R.']}, {'doi': '10.1007/s11192-014-1229-3', 'title': 'Disciplinary differences in Twitter scholarly communication', 'abstract': 'This paper investigates disciplinary differences in how researchers use the microblogging site Twitter. Tweets from selected researchers in ten disciplines (astrophysics, biochemistry, digital humanities, economics, history of science, cheminformatics, cognitive science, drug discovery, social network analysis, and sociology) were collected and analyzed both statistically and qualitatively. The researchers tended to share more links and retweet more than the average Twitter users in earlier research and there were clear disciplinary differences in how they used Twitter. Biochemists retweeted substantially more than researchers in the other disciplines. Researchers in digital humanities and cognitive science used Twitter more for conversations, while researchers in economics shared the most links. Finally, whilst researchers in biochemistry, astrophysics, cheminformatics and digital humanities seemed to use Twitter for scholarly communication, scientific use of Twitter in economics, sociology and history of science appeared to be marginal. © 2014, Akadémiai Kiadó, Budapest, Hungary.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892447024&doi=10.1007%2fs11192-014-1229-3&partnerID=40&md5=0f4e0be141475ec6e96b15cb15d1be9c', 'citations': 182, 'keywords': ['Altmetrics', 'Disciplinary differences', 'Scholarly communication', 'Twitter', 'Webometrics'], 'authors': ['Holmberg K.', 'Thelwall M.']}, {'doi': '10.1177/1461444812465137', 'title': 'Towards a sociology of computational and algorithmic journalism', 'abstract': 'This article advances a sociological approach to computational journalism. By \"computational journalism\" the article refers to the increasingly ubiquitous forms of algorithmic, social scientific, and mathematical forms of newswork adopted by many 21st-century newsrooms and touted by many educational institutions as \"the future of news.\" By \"sociological approach,\" the article endorses a research model that brackets, at least temporarily, many of the current industry concerns with the practical usability of newsroom analysis. The bulk of the article outlines a series of six lenses through which such an approach to computational journalism might be carried out. Four of these lenses are drawn from Schudson\\'s classic typology of the sociology of news-economic, political, cultural, and organizational approaches. In addition, the author adds Bordieuean field approaches and technological lenses to the mix. In each instance, the author discusses how particular approaches might need to be modified in order to study computational journalism in the digital age. © The Author(s) 2012.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885769193&doi=10.1177%2f1461444812465137&partnerID=40&md5=a20bafd34c1504f04f5c8bdb72857f46', 'citations': 181, 'keywords': ['Computational journalism', 'culture', 'data', 'digital humanities', 'ethnography', 'journalism', 'news institutionalism', 'political economy'], 'authors': ['Anderson C.W.']}, {'doi': '10.1007/s10994-013-5413-0', 'title': 'Interactive topic modeling', 'abstract': 'Topic models are a useful and ubiquitous tool for understanding large corpora. However, topic models are not perfect, and for many users in computational social science, digital humanities, and information studies - who are not machine learning experts - existing models and frameworks are often a \"take it or leave it\" proposition. This paper presents a mechanism for giving users a voice by encoding users\\' feedback to topic models as correlations between words into a topic model. This framework, interactive topic modeling (itm), allows untrained users to encode their feedback easily and iteratively into the topic models. Because latency in interactive systems is crucial, we develop more efficient inference algorithms for tree-based topic models. We validate the framework both with simulated and real users. © 2013 The Author(s).', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901496744&doi=10.1007%2fs10994-013-5413-0&partnerID=40&md5=5e9f7ce6d9daf635fb278501a9243d93', 'citations': 144, 'keywords': ['Feedback', 'Gibbs sampling', 'Interactive topic modeling', 'Latent Dirichlet Allocation', 'Online learning', 'Topic models'], 'authors': ['Hu Y.', 'Boyd-Graber J.', 'Satinoff B.', 'Smith A.']}, {'doi': '10.1108/00220411111109449', 'title': 'Enabled backchannel: conference Twitter use by digital humanists', 'abstract': \"Purpose – To date, few studies have been undertaken to make explicit how microblogging technologies are used by and can benefit scholars. This paper aims to investigate the use of Twitter by an academic community in various conference settings, and to pose the following questions: Does the use of a Twitter\\ue4f8enabled backchannel enhance the conference experience, collaboration and the co\\ue4f8construction of knowledge? and How is microblogging used within academic conferences, and can one articulate the benefits it may bring to a discipline? Design/methodology/approach This paper considers the use of Twitter as a digital backchannel by the Digital Humanities (DH) community, taking as its focus postings to Twitter during three different international 2009 conferences. The resulting archive of 4,574 “Tweets” was analysed using various quantitative and qualitative methods, including a qualitative categorisation of Twitter posts by open coded analysis, a quantitative examination of user conventions, and text analysis tools. Prominent Tweeters were identified and a small qualitative survey was undertaken to ascertain individuals' attitudes towards a Twitter\\ue4f8enabled backchannel. Findings – Conference hashtagged Twitter activity does not constitute a single distributed conversation, but rather multiple monologues with a few intermittent, discontinuous, loosely joined dialogues between users. The digital backchannel constitutes a multidirectional complex space in which the users make notes, share resources, hold discussions and ask questions as well as establishing a clear individual online presence. The use of Twitter as a conference platform enables the community to expand communication and participation in events amongst its members. The analysis revealed the close\\ue4f8knit nature of the DH researcher community, which may be somewhat intimidating for those new to the field or conference. Practical implications This study has indicated that, given that Twitter is becoming increasingly important for academic communities, new, dedicated methodologies for the analysis and understanding of Tweet\\ue4f8based corpora are necessary. Routinely used textual analysis tools cannot be applied to corpora of Tweets in a straightforward manner, due to the creative and fragmentary nature of language used within microblogging. In this paper, a method has been suggested to categorise Tweets using open coded analysis to facilitate understanding of Tweet\\ue4f8based corpora, which could be adopted elsewhere. Originality/value – This paper is the first known exhaustive study that concentrates on how microblogging technologies such as Twitter are used by and can benefit scholars. This data set both provides a valuable insight into the prevalence of a variety of Twitter practices within the constraints of a conference setting, and highlights the need for methodologies to be developed to analyse social media streams such as Twitter feeds. It also provides a bibliography of other research into microblogging. © 2011, Emerald Group Publishing Limited\", 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952292203&doi=10.1108%2f00220411111109449&partnerID=40&md5=63335e5ffd7293ab3b3c3a465d083c7a', 'citations': 144, 'keywords': ['Conferences', 'Digital communication systems', 'Social networks', 'User studies'], 'authors': ['Ross C.', 'Terras M.', 'Warwick C.', 'Welsh A.']}, {'doi': '10.1108/AJIM-09-2013-0094', 'title': 'Programmed method: Developing a toolset for capturing and analyzing tweets', 'abstract': 'Purpose–The purpose of this paper is to introduce Digital Methods Initiative Twitter Capture and Analysis Toolset, a toolset for capturing and analyzing Twitter data. Instead of just presenting a technical paper detailing the system, however, the authors argue that the type of data used for, as well as the methods encoded in, computational systems have epistemological repercussions for research. The authors thus aim at situating the development of the toolset in relation to methodological debates in the social sciences and humanities. Design/methodology/approach–The authors review the possibilities and limitations of existing approaches to capture and analyze Twitter data in order to address the various ways in which computational systems frame research. The authors then introduce the open-source toolset and put forward an approach that embraces methodological diversity and epistemological plurality. Findings–The authors find that design decisions and more general methodological reasoning can and should go hand in hand when building tools for computational social science or digital humanities. Practical implications–Besides methodological transparency, the software provides robust and reproducible data capture and analysis, and interlinks with existing analytical software. Epistemic plurality is emphasized by taking into account how Twitter structures information, by allowing for a number of different sampling techniques, by enabling a variety of analytical approaches or paradigms, and by facilitating work at the micro, meso, and macro levels. Originality/value–The paper opens up critical debate by connecting tool design to fundamental interrogations of methodology and its repercussions for the production of knowledge. The design of the software is inspired by exchanges and debates with scholars from a variety of disciplines and the attempt to propose a flexible and extensible tool that accommodates a wide array of methodological approaches is directly motivated by the desire to keep computational work open for various epistemic sensibilities. © Emerald Group Publishing Limited.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928249663&doi=10.1108%2fAJIM-09-2013-0094&partnerID=40&md5=503326daa805093e265cece8d666ac3d', 'citations': 143, 'keywords': ['Analysis', 'Computational social science', 'Data collection', 'Digital humanities', 'Digital methods', 'Twitter'], 'authors': ['Borra E.', 'Rieder B.']}, {'doi': '10.32614/rj-2016-007', 'title': 'Stylometry with R: A package for computational text analysis', 'abstract': \"This software paper describes 'Stylometry with R' (stylo), a flexible R package for the highlevel analysis of writing style in stylometry. Stylometry (computational stylistics) is concerned with the quantitative study of writing style, e.g. authorship verification, an application which has considerable potential in forensic contexts, as well as historical research. In this paper we introduce the possibilities of stylo for computational text analysis, via a number of dummy case studies from English and French literature. We demonstrate how the package is particularly useful in the exploratory statistical analysis of texts, e.g. with respect to authorial writing style. Because stylo provides an attractive graphical user interface for high-level exploratory analyses, it is especially suited for an audience of novices, without programming skills (e.g. from the Digital Humanities). More experienced users can benefit from our implementation of a series of standard pipelines for text processing, as well as a number of similarity metrics.\", 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010281284&doi=10.32614%2frj-2016-007&partnerID=40&md5=7bc156d9c817b635cf13a9dd554f5ba3', 'citations': 134, 'keywords': [], 'authors': ['Eder M.', 'Rybicki J.', 'Kestemont M.']}, {'doi': '10.1080/01916599.2012.714635', 'title': \"What's the Big Idea? Intellectual History and the Longue Durée\", 'abstract': 'Historians of all kinds are beginning to return to temporally expansive studies after decades of aversion and neglect. There are even signs that intellectual historians are returning to the longue durée. What are the reasons for this revival of long-range intellectual history? And how might it be rendered methodologically robust as well as historically compelling? This article proposes a model of transtemporal history, proceeding via serial contextualism to create a history in ideas spanning centuries, even millennia: key examples come from work in progress on ideas of civil war from ancient Rome to the present. The article concludes with brief reflections on the potential impact of the digital humanities on the practice of long-range intellectual history. © 2012 Copyright Taylor and Francis Group, LLC.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868280635&doi=10.1080%2f01916599.2012.714635&partnerID=40&md5=3b5e264dcffa6a16aad5f2d68dfad625', 'citations': 109, 'keywords': ['Cambridge School', 'civil war', 'conceptual history', 'digital humanities', 'longue durée'], 'authors': ['Armitage D.']}, {'doi': '10.1111/j.1475-5661.2010.00405.x', 'title': 'Mapping the English Lake District: A literary GIS', 'abstract': \"To date, much of the work that uses Geographical Information Systems (GIS) to study human geographies applies a social science paradigm to quantitative data. There is a growing recognition of the need, however, to test whether GIS can be used to map out the qualitative 'data' provided by the articulation of subjective spatial experiences. This paper expands the conceptual possibilities opened up by the use of GIS technology through an exploration of the theoretical potentiality of literary GIS. Drawing on work carried out as part of an interdisciplinary project, 'Mapping the Lakes', the paper focuses on the ways in which GIS can be used to explore the spatial relationships between two textual accounts of tours of the English Lake District: the proto-Picturesque journey undertaken by the poet, Thomas Gray, in the autumn of 1769; and Samuel Taylor Coleridge's self-consciously post-Picturesque 'circumcursion' of August 1802. Alongside this text-specific focus, the paper also draws on recent spatial literary criticism to reflect, more generally, on the critical possibilities and problems associated with the digital mapping of space and place in literature. Ultimately, the paper seeks to open up methodological and critical space for the ongoing development of literary GIS. © 2010 The Authors. Transactions of the Institute of British Geographers © 2010 Royal Geographical Society (with the Institute of British Geographers).\", 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649784112&doi=10.1111%2fj.1475-5661.2010.00405.x&partnerID=40&md5=a49abb3528b15ede2dd5067792dd83e5', 'citations': 93, 'keywords': ['Digital humanities', 'English Lake District', 'GIS', 'Literary cartography', 'Literary studies', 'Spatial theory'], 'authors': ['Cooper D.', 'Gregory I.N.']}, {'doi': '10.1177/0309132512444063', 'title': 'Crossing the qualitative- quantitative divide II: Inventive approaches to big data, mobile methods, and rhythmanalysis', 'abstract': 'In this second of three reports on qualitative and quantitative methods we highlight novel methods with particular purchase on the problems of our time. We again focus on scholarship crossing multiple geographical divides, those of neo/paleo geography, qualitative/quantitative methods, and physical/human geography. We do so now by concentrating on three areas: the emerging digital humanities and the rise of big data, mobile methods, and rhythmanalysis. With this broad approach we seek also to encourage consilience, synergy, and a positive embrace of diversity in geographical scholarship. © The Author(s) 2012.', 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875024343&doi=10.1177%2f0309132512444063&partnerID=40&md5=515741df9a331ef610192a73dfcc8080', 'citations': 89, 'keywords': ['big data', 'digital humanities', 'inventive methods', 'methodology', 'mobile methods', 'mobilities', 'qualitative', 'quantitative'], 'authors': ['DeLyser D.', 'Sui D.']}]\n"
          ]
        }
      ],
      "source": [
        "print(processed_10papers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'doi': '10.1177/2053951714528481', 'title': 'Big Data, new epistemologies and paradigm shifts', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'This article examines how the availability of Big Data, coupled with new data analytics, challenges established epistemologies across the sciences, social sciences and humanities. In particular, it critically explores new forms of empiricism that declare ‘the end of theory’ and the creation of data-driven rather than knowledge-driven science.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': ' This article examines how the availability of Big Data, coupled with new data analytics, challenges established epistemologies across the sciences, social sciences and humanities . In particular, it critically explores new forms of empiricism that declare ‘the end of theory’ and the creation of data-driven rather than knowledge-driven science .'}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'Big Data and new data analytics are disruptive innovations which are reconfiguring in many instances how research is conducted. There is an urgent need for a critical reflection within the academy on the epistemological implications of the unfolding data revolution. A potentially fruitful approach would be the development of a situated, reflexive and contextually nuanced epistemology.'}, {'model': 'google/pegasus-large', 'summarized_text': 'This article examines how the availability of Big Data, coupled with new data analytics, challenges established epistemologies across the sciences, social sciences and humanities, and assesses the extent to which they are engendering paradigm shifts across multiple disciplines.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'The availability of Big Data and new data analytics challenges established epistemologies across the sciences, social sciences and humanities . It assesses the extent to which they are engendering paradigm shifts across multiple disciplines .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073682542&doi=10.1177%2f2053951714528481&partnerID=40&md5=49cbcd64a939cb47af2f8996d0c114a2', 'citations': 1062, 'keywords': ['Big Data', 'computational social sciences', 'data analytics', 'data-driven science', 'digital humanities', 'end of theory', 'epistemology', 'paradigms']}, {'doi': '10.1007/s11192-014-1229-3', 'title': 'Disciplinary differences in Twitter scholarly communication', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'This paper investigates disciplinary differences in how researchers use the microblogging site Twitter. Tweets from selected researchers in ten disciplines were collected and analyzed both statistically and qualitatively. The researchers tended to share more links and retweet more than the average Twitter users in earlier research. Biochemists retweeted substantially more than researchers in the other disciplines.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': ' This paper investigates disciplinary differences in how researchers use Twitter . Tweets from selected researchers in ten disciplines were collected and analyzed both statistically and qualitatively . Biochemists retweeted substantially more than researchers in the other disciplines . Researchers in digital humanities and cognitive science used Twitter more for conversations, while researchers in economics shared the most links .'}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'This paper investigates disciplinary differences in how researchers use the microblogging site Twitter. Tweets from selected researchers in ten disciplines were collected and analyzed both statistically and qualitatively. The researchers tended to share more links and retweet more than the average Twitter user. Biochemists retweeted substantially more than researchers in the other disciplines. Researchers in digital humanities used Twitter more for conversations, while researchers in economics shared the most links.'}, {'model': 'google/pegasus-large', 'summarized_text': 'Finally, whilst researchers in biochemistry, astrophysics, cheminformatics and digital humanities seemed to use Twitter for scholarly communication, scientific use of Twitter in economics, sociology and history of science appeared to be marginal.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'The researchers tended to share more links and retweet more than the average Twitter users . Biochemists retweeted substantially more than researchers in the other disciplines .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892447024&doi=10.1007%2fs11192-014-1229-3&partnerID=40&md5=0f4e0be141475ec6e96b15cb15d1be9c', 'citations': 182, 'keywords': ['Altmetrics', 'Disciplinary differences', 'Scholarly communication', 'Twitter', 'Webometrics']}, {'doi': '10.1177/1461444812465137', 'title': 'Towards a sociology of computational and algorithmic journalism', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'This article advances a sociological approach to computational journalism. By \"computational journalism\" the article refers to the increasingly ubiquitous forms of algorithmic, social scientific, and mathematical forms of newswork. Four of these lenses are drawn from Schudson\\'s classic typology of the sociology of news-economic, political, cultural, and organizational approaches. In addition, the author adds Bordieuean field approaches and technological lenses to the mix.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': \" This article advances a sociological approach to computational journalism . The bulk of the article outlines a series of six lenses through which such an approach might be carried out . Four of these lenses are drawn from Schudson's classic typology of the sociology of news-economic, political, cultural, and organizational approaches . In each instance, the author discusses how particular approaches might need to be modified .\"}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': \"This article advances a sociological approach to computational journalism. Four of the lenses are drawn from Schudson's classic typology of the sociology of news-economic, political, cultural, and organizational approaches. The author adds Bordieuean field approaches and technological lenses to the mix.\"}, {'model': 'google/pegasus-large', 'summarized_text': 'The bulk of the article outlines a series of six lenses through which such an approach to computational journalism might be carried out.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'The article refers to increasingly ubiquitous forms of algorithmic, social scientific, and mathematical forms of newswork adopted by many 21st-century newsrooms . The article endorses a research model that brackets, at least temporarily, many of the current industry concerns with the practical usability of newsroom analysis .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885769193&doi=10.1177%2f1461444812465137&partnerID=40&md5=a20bafd34c1504f04f5c8bdb72857f46', 'citations': 181, 'keywords': ['Computational journalism', 'culture', 'data', 'digital humanities', 'ethnography', 'journalism', 'news institutionalism', 'political economy']}, {'doi': '10.1007/s10994-013-5413-0', 'title': 'Interactive topic modeling', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': ' Topic models are a useful and ubiquitous tool for understanding large corpora. For many users in computational social science, digital humanities, and information studies - who are not machine learning experts - existing models and frameworks are often a \"take it or leave it\" proposition. This paper presents a mechanism for giving users a voice by encoding users\\' feedback to topic models.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': \" Topic models are useful and ubiquitous tool for understanding large corpora, but topic models are not perfect . This paper presents a mechanism for giving users a voice by encoding users' feedback to topic models as correlations between words into a topic model . This framework, interactive topic modeling (itm), allows untrained users to encode their feedback easily and iteratively into the topic models .\"}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'Topic models are useful tool for understanding large corpora, but not perfect. Interactive topic modeling allows untrained users to encode their feedback easily and iteratively into the topic models. The paper developed more efficient inference algorithms for tree-based topic models and validated the framework with simulated and real users.'}, {'model': 'google/pegasus-large', 'summarized_text': 'This framework, interactive topic modeling (itm), allows untrained users to encode their feedback easily and iteratively into the topic models.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'We develop more efficient inference algorithms for tree-based topic models . We validate the framework both with simulated and real users .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901496744&doi=10.1007%2fs10994-013-5413-0&partnerID=40&md5=5e9f7ce6d9daf635fb278501a9243d93', 'citations': 144, 'keywords': ['Feedback', 'Gibbs sampling', 'Interactive topic modeling', 'Latent Dirichlet Allocation', 'Online learning', 'Topic models']}, {'doi': '10.1108/00220411111109449', 'title': 'Enabled backchannel: conference Twitter use by digital humanists', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'Few studies have been undertaken to make explicit how microblogging technologies are used by and can benefit scholars. This paper considers the use of Twitter as a digital backchannel by the Digital Humanities (DH) community. The resulting archive of 4,574 “Tweets” was analysed using various quantitative and qualitative methods.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': ' Few studies have been undertaken to make explicit how microblogging technologies are used by and can benefit scholars . This paper considers the use of Twitter as a digital backchannel by the Digital Humanities (DH) community . The analysis revealed the close-knit nature of the DH researcher community, which may be somewhat intimidating for those new to the field or conference .'}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'This paper considers the use of Twitter as a digital backchannel by the Digital Humanities community at three international 2009 conferences. The archive of 4,574 Tweets was analysed using various quantitative and qualitative methods. The analysis revealed the close-knit nature of the DH researcher community.'}, {'model': 'google/pegasus-large', 'summarized_text': 'This paper aims to investigate the use of Twitter by an academic community in various conference settings, and to pose the following questions: Does the use of a Twitterenabled backchannel enhance the conference experience, collaboration and the coconstruction of knowledge? Design/methodology/approach This paper considers the use of Twitter as a digital backchannel by the Digital Humanities (DH) community, taking as its focus postings to Twitter during three different international 2009 conferences. In this paper, a method has been suggested to categorise Tweets using open coded analysis to facilitate understanding of Tweetbased corpora, which could be adopted elsewhere.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': \"This paper aims to investigate the use of Twitter by an academic community in various conference settings . The archive of 4,574 'Tweets' was analysed using various quantitative and qualitative methods . The analysis revealed the closeknit nature of the DH researcher community, which may be somewhat intimidating for those new to the field or conference .\"}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952292203&doi=10.1108%2f00220411111109449&partnerID=40&md5=63335e5ffd7293ab3b3c3a465d083c7a', 'citations': 144, 'keywords': ['Conferences', 'Digital communication systems', 'Social networks', 'User studies']}, {'doi': '10.1108/AJIM-09-2013-0094', 'title': 'Programmed method: Developing a toolset for capturing and analyzing tweets', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'Digital Methods Initiative Twitter Capture and Analysis Toolset is a toolset for capturing and analyzing Twitter data. The authors aim at situating the development of the toolset in relation to methodological debates in the social sciences and humanities. The software provides robust and reproducible data capture and analysis, and interlinks with existing analytical software.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': ' Digital Methods Initiative Twitter Capture and Analysis Toolset is a toolset for capturing and analyzing Twitter data . The authors argue that the type of data used for, as well as the methods encoded in, computational systems have epistemological repercussions for research . They aim at situating the development of the toolset in relation to methodological debates in the social sciences and humanities .'}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'Digital Methods Initiative Twitter Capture and Analysis Toolset is a toolset for capturing and analyzing Twitter data. The design of the software is inspired by exchanges and debates with scholars from a variety of disciplines. The aim is to keep computational work open for various epistemic sensibilities.'}, {'model': 'google/pegasus-large', 'summarized_text': 'Design/methodology/approach–The authors review the possibilities and limitations of existing approaches to capture and analyze Twitter data in order to address the various ways in which computational systems frame research.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'The purpose of this paper is to introduce Digital Methods Initiative Twitter Capture and Analysis Toolset, a toolset for capturing and analyzing Twitter data . The authors aim at situating the development of the toolset in relation to methodological debates in the social sciences and humanities .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928249663&doi=10.1108%2fAJIM-09-2013-0094&partnerID=40&md5=503326daa805093e265cece8d666ac3d', 'citations': 143, 'keywords': ['Analysis', 'Computational social science', 'Data collection', 'Digital humanities', 'Digital methods', 'Twitter']}, {'doi': '10.32614/rj-2016-007', 'title': 'Stylometry with R: A package for computational text analysis', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'Stylometry (computational stylistics) is concerned with the quantitative study of writing style. Stylo provides an attractive graphical user interface for high-level exploratory analyses. It is especially suited for an audience of novices, without programming skills (e.g. from the Digital Humanities)'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': \" This software paper describes 'Stylometry with R' (stylo), a flexible R package for the highlevel analysis of writing style in stylometry . Stylometry (computational stylistics) is concerned with the quantitative study of . writing style, e.g. authorship verification . This application has considerable potential in forensic contexts, as well as historical research .\"}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'Stylometry with R (stylo) is a flexible R package for the high level analysis of writing style in stylometry. Stylometry (computational stylistics) is concerned with the quantitative study of the writing style. It has potential in forensic contexts, as well as historical research.'}, {'model': 'google/pegasus-large', 'summarized_text': \"This software paper describes 'Stylometry with R' (stylo), a flexible R package for the highlevel analysis of writing style in stylometry.\"}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': \"'Stylometry with R' (stylo) is a flexible R package for the highlevel analysis of writing style in stylometry . Stylometry (computational stylistics) is concerned with the quantitative study of writing style .\"}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010281284&doi=10.32614%2frj-2016-007&partnerID=40&md5=7bc156d9c817b635cf13a9dd554f5ba3', 'citations': 134, 'keywords': []}, {'doi': '10.1080/01916599.2012.714635', 'title': \"What's the Big Idea? Intellectual History and the Longue Durée\", 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'Historians of all kinds are beginning to return to temporally expansive studies. What are the reasons for this revival of long-range intellectual history? And how might it be rendered methodologically robust as well as historically compelling? This article proposes a model of transtemporal history, proceeding via serial contextualism.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': ' Historians of all kinds are beginning to return to temporally expansive studies after decades of aversion and neglect . This article proposes a model of transtemporal history, proceeding via serial contextualism to create a history in ideas spanning centuries, even millennia . Key examples come from work in progress on ideas of civil war from ancient Rome to the present .'}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'There are signs that historians are returning to long-range intellectual history. This article proposes a model of transtemporal history, proceeding via serial contextualism to create a history in ideas spanning centuries and millennia. The article concludes with reflections on the potential impact of the digital humanities on the practice of long-distance history.'}, {'model': 'google/pegasus-large', 'summarized_text': 'The article concludes with brief reflections on the potential impact of the digital humanities on the practice of long-range intellectual history.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'Historians of all kinds are returning to temporally expansive studies after decades of aversion and neglect . This article proposes a model of transtemporal history, proceeding via serial contextualism to create a history in ideas spanning centuries, even millennia .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868280635&doi=10.1080%2f01916599.2012.714635&partnerID=40&md5=3b5e264dcffa6a16aad5f2d68dfad625', 'citations': 109, 'keywords': ['Cambridge School', 'civil war', 'conceptual history', 'digital humanities', 'longue durée']}, {'doi': '10.1111/j.1475-5661.2010.00405.x', 'title': 'Mapping the English Lake District: A literary GIS', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': \"This paper expands the conceptual possibilities opened up by the use of GIS technology through an exploration of the theoretical potentiality of literary GIS. Drawing on work carried out as part of an interdisciplinary project, 'Mapping the Lakes', the paper focuses on the ways in which GIS can be used to explore the spatial relationships between two textual accounts of tours.\"}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': \" This paper expands the conceptual possibilities opened up by the use of GIS technology through an exploration of the theoretical potentiality of literary GIS . Drawing on work carried out as part of an interdisciplinary project, 'Mapping the Lakes', the paper focuses on the ways in which GIS can be used to explore the spatial relationships between two textual accounts of tours of the English Lake District .\"}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': \"This paper explores the theoretical potentiality of literary GIS. It is based on work carried out as part of an interdisciplinary project, 'Mapping the Lakes'. The paper focuses on the spatial relationships between two textual accounts of tours of the English Lake District: Thomas Gray's in the autumn of 1769 and Samuel Taylor Coleridge's in August 1802.\"}, {'model': 'google/pegasus-large', 'summarized_text': 'Alongside this text-specific focus, the paper also draws on recent spatial literary criticism to reflect, more generally, on the critical possibilities and problems associated with the digital mapping of space and place in literature.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'This paper expands the conceptual possibilities opened up by the use of GIS technology . It focuses on the ways in which GIS can be used to explore the spatial relationships between two textual accounts of tours of the English Lake District . Ultimately, the paper seeks to open up methodological and critical space for the ongoing development of literary GIS .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649784112&doi=10.1111%2fj.1475-5661.2010.00405.x&partnerID=40&md5=a49abb3528b15ede2dd5067792dd83e5', 'citations': 93, 'keywords': ['Digital humanities', 'English Lake District', 'GIS', 'Literary cartography', 'Literary studies', 'Spatial theory']}, {'doi': '10.1177/0309132512444063', 'title': 'Crossing the qualitative- quantitative divide II: Inventive approaches to big data, mobile methods, and rhythmanalysis', 'summ_abstract': [{'model': 'facebook/bart-large-cnn', 'summarized_text': 'In this second of three reports on qualitative and quantitative methods we highlight novel methods with particular purchase on the problems of our time. We again focus on scholarship crossing multiple geographical divides, those of neo/paleo geography, qualitative/quantitative methods, and physical/human geography. We do so now by concentrating on three areas: the emerging digital humanities and the rise of big data.'}, {'model': 'sshleifer/distilbart-cnn-12-6', 'summarized_text': ' In this second of three reports on qualitative and quantitative methods we highlight novel methods with particular purchase on the problems of our time . We again focus on scholarship crossing multiple geographical divides, those of neo/paleo geography, qualitative/quantitative methods, and physical/human geography . With this broad approach we seek also to encourage consilience, synergy, and a positive embrace of diversity in geographical scholarship .'}, {'model': 'philschmid/bart-large-cnn-samsum', 'summarized_text': 'In the second of three reports on qualitative and quantitative methods we highlight novel methods with particular purchase on the problems of our time. We focus on scholarship crossing multiple geographical divides, those of neo/paleo geography, qualitative/quantitative methods, and physical/human geography.'}, {'model': 'google/pegasus-large', 'summarized_text': 'We again focus on scholarship crossing multiple geographical divides, those of neo/paleo geography, qualitative/quantitative methods, and physical/human geography.'}, {'model': 'sshleifer/distill-pegasus-cnn-16-4', 'summarized_text': 'In this second of three reports on qualitative and quantitative methods we highlight novel methods . We aim to encourage consilience, synergy and a positive embrace of diversity in geographical scholarship .'}], 'link': 'https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875024343&doi=10.1177%2f0309132512444063&partnerID=40&md5=515741df9a331ef610192a73dfcc8080', 'citations': 89, 'keywords': ['big data', 'digital humanities', 'inventive methods', 'methodology', 'mobile methods', 'mobilities', 'qualitative', 'quantitative']}]\n"
          ]
        }
      ],
      "source": [
        "print(processed_10summaries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. RAKE\n",
        "def rake_extractor(text):\n",
        "    \"\"\"\n",
        "    Uses Rake to extract the top 5 keywords from a text\n",
        "    Arguments: text (str)\n",
        "    Returns: list of keywords (list)\n",
        "    \"\"\"\n",
        "    r = Rake()\n",
        "    r.extract_keywords_from_text(text)\n",
        "    return r.get_ranked_phrases()[:10]\n",
        "\n",
        "# 2. YAKE\n",
        "def yake_extractor(text):\n",
        "    \"\"\"\n",
        "    Uses YAKE to extract the top 5 keywords from a text\n",
        "    Arguments: text (str)\n",
        "    Returns: list of keywords (list)\n",
        "    \"\"\"\n",
        "    keywords = yake.KeywordExtractor(lan=\"en\", n=3, windowsSize=3, top=10).extract_keywords(text)\n",
        "    results = []\n",
        "    for scored_keywords in keywords:\n",
        "        for keyword in scored_keywords:\n",
        "            if isinstance(keyword, str):\n",
        "                results.append(keyword) \n",
        "    return results \n",
        "\n",
        "\n",
        "# 3. PositionRank\n",
        "def position_rank_extractor(text):\n",
        "    \"\"\"\n",
        "    Uses PositionRank to extract the top 5 keywords from a text\n",
        "    Arguments: text (str)\n",
        "    Returns: list of keywords (list)\n",
        "    \"\"\"\n",
        "    # define the valid Part-of-Speeches to occur in the graph\n",
        "    pos = {'NOUN', 'PROPN', 'ADJ', 'ADV'}\n",
        "    extractor = pke.unsupervised.PositionRank()\n",
        "    extractor.load_document(text, language='en')\n",
        "    extractor.candidate_selection(maximum_word_number=5)\n",
        "    # 4. weight the candidates using the sum of their word's scores that are\n",
        "    #    computed using random walk biaised with the position of the words\n",
        "    #    in the document. In the graph, nodes are words (nouns and\n",
        "    #    adjectives only) that are connected if they occur in a window of\n",
        "    #    3 words.\n",
        "    extractor.candidate_weighting(window=3, pos=pos)\n",
        "    # 5. get the 5-highest scored candidates as keyphrases\n",
        "    keyphrases = extractor.get_n_best(n=10)\n",
        "    results = []\n",
        "    for scored_keywords in keyphrases:\n",
        "        for keyword in scored_keywords:\n",
        "            if isinstance(keyword, str):\n",
        "                results.append(keyword) \n",
        "    return results \n",
        "\n",
        "# 4. SingleRank\n",
        "def single_rank_extractor(text):\n",
        "    \"\"\"\n",
        "    Uses SingleRank to extract the top 5 keywords from a text\n",
        "    Arguments: text (str)\n",
        "    Returns: list of keywords (list)\n",
        "    \"\"\"\n",
        "    pos = {'NOUN', 'PROPN', 'ADJ', 'ADV'}\n",
        "    extractor = pke.unsupervised.SingleRank()\n",
        "    extractor.load_document(text, language='en')\n",
        "    extractor.candidate_selection(pos=pos)\n",
        "    extractor.candidate_weighting(window=3, pos=pos)\n",
        "    keyphrases = extractor.get_n_best(n=10)\n",
        "    results = []\n",
        "    for scored_keywords in keyphrases:\n",
        "        for keyword in scored_keywords:\n",
        "            if isinstance(keyword, str):\n",
        "                results.append(keyword) \n",
        "    return results \n",
        "\n",
        "# 5. MultipartiteRank\n",
        "def multipartite_rank_extractor(text):\n",
        "    \"\"\"\n",
        "    Uses MultipartiteRank to extract the top 5 keywords from a text\n",
        "    Arguments: text (str)\n",
        "    Returns: list of keywords (list)\n",
        "    \"\"\"\n",
        "    extractor = pke.unsupervised.MultipartiteRank()\n",
        "    extractor.load_document(text, language='en')\n",
        "    pos = {'NOUN', 'PROPN', 'ADJ', 'ADV'}\n",
        "    extractor.candidate_selection(pos=pos)\n",
        "    # 4. build the Multipartite graph and rank candidates using random walk,\n",
        "    #    alpha controls the weight adjustment mechanism, see TopicRank for\n",
        "    #    threshold/method parameters.\n",
        "    extractor.candidate_weighting(alpha=1.1, threshold=0.74, method='average')\n",
        "    keyphrases = extractor.get_n_best(n=10)\n",
        "    results = []\n",
        "    for scored_keywords in keyphrases:\n",
        "        for keyword in scored_keywords:\n",
        "            if isinstance(keyword, str):\n",
        "                results.append(keyword) \n",
        "    return results\n",
        "\n",
        "# 6. TopicRank\n",
        "def topic_rank_extractor(text):\n",
        "    \"\"\"\n",
        "    Uses TopicRank to extract the top 5 keywords from a text\n",
        "    Arguments: text (str)\n",
        "    Returns: list of keywords (list)\n",
        "    \"\"\"\n",
        "    extractor = pke.unsupervised.TopicRank()\n",
        "    extractor.load_document(text, language='en')\n",
        "    pos = {'NOUN', 'PROPN', 'ADJ', 'ADV'}\n",
        "    extractor.candidate_selection(pos=pos)\n",
        "    extractor.candidate_weighting()\n",
        "    keyphrases = extractor.get_n_best(n=10)\n",
        "    results = []\n",
        "    for scored_keywords in keyphrases:\n",
        "        for keyword in scored_keywords:\n",
        "            if isinstance(keyword, str):\n",
        "                results.append(keyword) \n",
        "    return results\n",
        "\n",
        "# 7. KeyBERT\n",
        "def keybert_extractor(text):\n",
        "    bert = KeyBERT()\n",
        "    \"\"\"\n",
        "    Uses KeyBERT to extract the top 5 keywords from a text\n",
        "    Arguments: text (str)\n",
        "    Returns: list of keywords (list)\n",
        "    \"\"\"\n",
        "    keywords = bert.extract_keywords(text, keyphrase_ngram_range=(1, 3), stop_words=\"english\", top_n=10)\n",
        "    results = []\n",
        "    for scored_keywords in keywords:\n",
        "        for keyword in scored_keywords:\n",
        "            if isinstance(keyword, str):\n",
        "                results.append(keyword)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class KeywordExtractor():\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        \n",
        "    def get_keywords(self, text):\n",
        "        if self.model == 'KEYBERT':\n",
        "            head = {'KEYBERT': keybert_extractor(text)}\n",
        "        elif self.model == 'TOPIC':\n",
        "            head = {'TOPIC RANK': topic_rank_extractor(text)} \n",
        "        elif self.model == 'MULTIPARTITE':\n",
        "            head = {'MULTIPARTITE RANK': multipartite_rank_extractor(text)}\n",
        "        elif self.model == 'SINGLE':\n",
        "            head = {'SINGLE RANK': single_rank_extractor(text)}\n",
        "        elif self.model == 'YAKE':\n",
        "            head = {'YAKE': yake_extractor(text)}\n",
        "        elif self.model == 'RAKE':\n",
        "            head = {'RAKE': rake_extractor(text)}\n",
        "        elif self.model == 'POSITION':\n",
        "            head = {'POSITION RANK': position_rank_extractor(text)}\n",
        "        else:\n",
        "            head = {}\n",
        "            \n",
        "        return head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def final_process_data(json_data):\n",
        "    \n",
        "    keyword_models=['KEYBERT', 'YAKE', 'RAKE', 'POSITION', 'SINGLE', 'MULTIPARTITE', 'TOPIC']\n",
        "    \n",
        "    data = []\n",
        "    \n",
        "    for i in json_data:\n",
        "        ex_keyword = KeywordExtractor(keyword)\n",
        "        s_abstract = ex_summarizer.get_summary(i.get('original').get('abstract'))\n",
        "        s_full = get_fulltext_summary(i, ex_summarizer)\n",
        "        s_article = ex_summarizer.get_summary(i.get('article').get('text'))\n",
        "        head = {\n",
        "            \"abstract\": {\n",
        "                \"title\": i.get('original').get('title'),\n",
        "                \"url\": i.get('original').get('url'),\n",
        "                \"abstract\": i.get('original').get('abstract'),\n",
        "                \"tokens\": len(nltk.word_tokenize(i.get('original').get('abstract'))),\n",
        "            },\n",
        "            \"full_text\": {\n",
        "                \"title\": i.get('original').get('title'),\n",
        "                \"url\": i.get('original').get('url'),\n",
        "                \"keywords\": i.get('original').get('keywords'),\n",
        "                \"text\": i.get('original').get('text'),\n",
        "                \"sections\": i.get('original').get('sections'),\n",
        "                \"tokens\": len(nltk.word_tokenize(i.get('original').get('text'))),\n",
        "            },\n",
        "            \"article\": {\n",
        "                \"title\": i.get('article').get('title'),\n",
        "                \"url\": i.get('article').get('url'),\n",
        "                \"keywords\": i.get('article').get('keywords'),\n",
        "                \"text\": i.get('article').get('text'),\n",
        "                \"tokens\": len(nltk.word_tokenize(i.get('article').get('text'))),\n",
        "            },\n",
        "            \"summaries\": {\n",
        "                \"abstract\": {\n",
        "                    \"text\": s_abstract,\n",
        "                    \"tokens\": len(nltk.word_tokenize(s_abstract)),\n",
        "                },\n",
        "                \"full_text\": {\n",
        "                    \"text\": s_full,\n",
        "                    \"tokens\": len(nltk.word_tokenize(s_full)),\n",
        "                },\n",
        "                \"article\": {\n",
        "                    \"text\": s_article,\n",
        "                    \"tokens\": len(nltk.word_tokenize(s_article)),\n",
        "                }\n",
        "            },\n",
        "            \"keywords\": {\n",
        "                \"abstract\": ex_keyword.get_keywords(i.get('original').get('abstract')),\n",
        "                \"full_text\": ex_keyword.get_keywords(i.get('original').get('text')),\n",
        "                \"article\": ex_keyword.get_keywords(i.get('article').get('text'))\n",
        "            }\n",
        "        }\n",
        "        data.append(head)\n",
        "    return data"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('profextra')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "d9c053a61acfdbdf1174e3d410b8ae0c87c7d4854c4a9812804c3f7123709dc5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
